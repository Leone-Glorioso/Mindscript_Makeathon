{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:19:51.732743Z",
     "iopub.status.busy": "2025-05-24T11:19:51.732495Z",
     "iopub.status.idle": "2025-05-24T11:21:36.683581Z",
     "shell.execute_reply": "2025-05-24T11:21:36.682816Z",
     "shell.execute_reply.started": "2025-05-24T11:19:51.732721Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n",
      "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n",
      "Successfully installed bitsandbytes-0.45.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:15:03.049675Z",
     "iopub.status.busy": "2025-05-24T11:15:03.048893Z",
     "iopub.status.idle": "2025-05-24T11:15:07.631225Z",
     "shell.execute_reply": "2025-05-24T11:15:07.629155Z",
     "shell.execute_reply.started": "2025-05-24T11:15:03.049634Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0.dev0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers\n",
    "# !huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:22:19.510770Z",
     "iopub.status.busy": "2025-05-24T11:22:19.510270Z",
     "iopub.status.idle": "2025-05-24T11:22:19.598165Z",
     "shell.execute_reply": "2025-05-24T11:22:19.597317Z",
     "shell.execute_reply.started": "2025-05-24T11:22:19.510747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Paste your token directly here as a string (yes, it's visible – be careful not to share this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:22:32.202582Z",
     "iopub.status.busy": "2025-05-24T11:22:32.202100Z",
     "iopub.status.idle": "2025-05-24T11:23:03.864193Z",
     "shell.execute_reply": "2025-05-24T11:23:03.863257Z",
     "shell.execute_reply.started": "2025-05-24T11:22:32.202550Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.51.3\n",
      "Uninstalling transformers-4.51.3:\n",
      "  Successfully uninstalled transformers-4.51.3\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-nwipe79q\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-nwipe79q\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 31f8a0fe8a7e2db1ee30bf32ed5976cd11f3283c\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.0.dev0) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.0.dev0) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.0.dev0) (1.1.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.53.0.dev0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.53.0.dev0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.53.0.dev0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.53.0.dev0) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.53.0.dev0) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.53.0.dev0) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.0.dev0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.0.dev0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.0.dev0) (2025.4.26)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.53.0.dev0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.53.0.dev0) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.53.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.53.0.dev0) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.53.0.dev0) (2024.2.0)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for transformers: filename=transformers-4.53.0.dev0-py3-none-any.whl size=11365971 sha256=87ed7fb2322c86935fb8c1fb8b7c0b0ece9e42a2dcc35ef44c09cb311238401f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ulff_f59/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.53.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers\n",
    "!pip install git+https://github.com/huggingface/transformers.git --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:23:14.001739Z",
     "iopub.status.busy": "2025-05-24T11:23:14.000949Z",
     "iopub.status.idle": "2025-05-24T11:26:23.907520Z",
     "shell.execute_reply": "2025-05-24T11:26:23.906946Z",
     "shell.execute_reply.started": "2025-05-24T11:23:14.001709Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 11:23:27.568507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748085807.746705      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748085807.794720      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9520588a5c1b4f3095771941367758d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc94777c9a840bdbbf3c1369a0fc836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c60cf7fc6e9473a8e6f158878832049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc24aeb70874c5bb988acb69eec34a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4fe8a5c0214dd9a008c81d44c1fe34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f3874e2f344ac7a11ebfbc528940a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a725a14da78640deb603d102a6593b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497297472871404fb1ab98e125fd9dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a2e328b3b6426893cf81db8ac87b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd6c54a580f4a5b94ad320e10f7c177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8982c54cdba48438554a26adb7ea0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "# Replace with any LLaMA model you have access to\n",
    "model_id = \"meta-llama/Llama-2-7b-chat-hf\"  # or Llama-3-8b-instruct if available\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True  # Save memory\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=300,\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:27:26.993236Z",
     "iopub.status.busy": "2025-05-24T11:27:26.992550Z",
     "iopub.status.idle": "2025-05-24T11:27:26.998546Z",
     "shell.execute_reply": "2025-05-24T11:27:26.997845Z",
     "shell.execute_reply.started": "2025-05-24T11:27:26.993212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "chat_template = \"\"\"\n",
    "You are an AI assistant for an insurance company. Be helpful and polite.\n",
    "\n",
    "Client says: {query}\n",
    "\n",
    "Your reply:\n",
    "\"\"\"\n",
    "\n",
    "extract_template = \"\"\"\n",
    "Extract the following information from the client message:\n",
    "\n",
    "- Full Name\n",
    "- Date of Birth\n",
    "- Insurance Type\n",
    "- Description of Issue\n",
    "- Policy Number\n",
    "\n",
    "Only respond in JSON format:\n",
    "{{\n",
    "  \"name\": \"...\",\n",
    "  \"dob\": \"...\",\n",
    "  \"insurance_type\": \"...\",\n",
    "  \"issue_description\": \"...\",\n",
    "  \"policy_number\": \"...\"\n",
    "}}\n",
    "\n",
    "Client message: {query}\n",
    "\"\"\"\n",
    "\n",
    "# 🧠 Chatbot logic\n",
    "def insurance_chat(query):\n",
    "    # Compose prompts\n",
    "    chat_prompt = chat_template.format(query=query)\n",
    "    extract_prompt = extract_template.format(query=query)\n",
    "\n",
    "    # Generate response\n",
    "    response = pipe(chat_prompt)[0]['generated_text'].split(\"Your reply:\")[-1].strip()\n",
    "    extracted = pipe(extract_prompt)[0]['generated_text'].split(\"```json\")[-1].strip()\n",
    "\n",
    "    # Show results\n",
    "    print(\"🤖 Assistant:\\n\", response)\n",
    "    print(\"\\n📄 Extracted Info:\\n\", extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:31:57.037164Z",
     "iopub.status.busy": "2025-05-24T11:31:57.036894Z",
     "iopub.status.idle": "2025-05-24T11:31:57.056226Z",
     "shell.execute_reply": "2025-05-24T11:31:57.055605Z",
     "shell.execute_reply.started": "2025-05-24T11:31:57.037142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "chat_template = \"\"\"\n",
    "You are an AI assistant for an insurance company. Be helpful and polite.\n",
    "\n",
    "Client says: {query}\n",
    "\n",
    "Your reply:\n",
    "\"\"\"\n",
    "\n",
    "extract_template = \"\"\"\n",
    "Extract the following information from the client message:\n",
    "\n",
    "- Full Name\n",
    "- Date of Birth\n",
    "- Insurance Type\n",
    "- Description of Issue\n",
    "- Policy Number\n",
    "\n",
    "Respond only with a valid JSON object:\n",
    "{{\n",
    "  \"name\": \"...\",\n",
    "  \"dob\": \"...\",\n",
    "  \"insurance_type\": \"...\",\n",
    "  \"issue_description\": \"...\",\n",
    "  \"policy_number\": \"...\"\n",
    "}}\n",
    "\n",
    "Client message: {query}\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "def insurance_chat(query):\n",
    "    # Compose prompts\n",
    "    chat_prompt = chat_template.format(query=query)\n",
    "    extract_prompt = extract_template.format(query=query)\n",
    "\n",
    "    # Generate chat response\n",
    "    response_raw = pipe(chat_prompt)[0]['generated_text']\n",
    "    response = response_raw.split(\"Your reply:\")[-1].strip()\n",
    "\n",
    "    # Generate structured extraction\n",
    "    extracted_raw = pipe(extract_prompt)[0]['generated_text'].strip()\n",
    "\n",
    "    # Try to parse the JSON output\n",
    "    try:\n",
    "        extracted_json = json.loads(extracted_raw)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"⚠️ JSON parsing failed. Raw output:\\n\", extracted_raw)\n",
    "        extracted_json = None\n",
    "\n",
    "    # Show results\n",
    "    print(\"🤖 Assistant:\\n\", response)\n",
    "    print(\"\\n📄 Extracted Info:\\n\", extracted_json if extracted_json else extracted_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:32:02.193359Z",
     "iopub.status.busy": "2025-05-24T11:32:02.192834Z",
     "iopub.status.idle": "2025-05-24T11:32:06.732945Z",
     "shell.execute_reply": "2025-05-24T11:32:06.732328Z",
     "shell.execute_reply.started": "2025-05-24T11:32:02.193337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message:\n",
      "\n",
      "- Full Name\n",
      "- Date of Birth\n",
      "- Insurance Type\n",
      "- Description of Issue\n",
      "- Policy Number\n",
      "\n",
      "Respond only with a valid JSON object:\n",
      "{\n",
      "  \"name\": \"...\",\n",
      "  \"dob\": \"...\",\n",
      "  \"insurance_type\": \"...\",\n",
      "  \"issue_description\": \"...\",\n",
      "  \"policy_number\": \"...\"\n",
      "}\n",
      "\n",
      "Client message: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?\n",
      "\n",
      "Please provide your insurance details and policy number so we can process your claim.\n",
      "🤖 Assistant:\n",
      " Of course, Ms. Chen! I'm so sorry to hear that your car broke down. Can you please provide me with more details about the situation? Where exactly did it happen and what time did it occur? Additionally, do you have any idea what might have caused the breakdown? Any information you can provide will help us assist you better.\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message:\n",
      "\n",
      "- Full Name\n",
      "- Date of Birth\n",
      "- Insurance Type\n",
      "- Description of Issue\n",
      "- Policy Number\n",
      "\n",
      "Respond only with a valid JSON object:\n",
      "{\n",
      "  \"name\": \"...\",\n",
      "  \"dob\": \"...\",\n",
      "  \"insurance_type\": \"...\",\n",
      "  \"issue_description\": \"...\",\n",
      "  \"policy_number\": \"...\"\n",
      "}\n",
      "\n",
      "Client message: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?\n",
      "\n",
      "Please provide your insurance details and policy number so we can process your claim.\n"
     ]
    }
   ],
   "source": [
    "insurance_chat(\"Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:35:07.034388Z",
     "iopub.status.busy": "2025-05-24T11:35:07.033747Z",
     "iopub.status.idle": "2025-05-24T11:35:07.038267Z",
     "shell.execute_reply": "2025-05-24T11:35:07.037546Z",
     "shell.execute_reply.started": "2025-05-24T11:35:07.034367Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "chat_template = \"\"\"\n",
    "Είσαι ένας βοηθητικός και ευγενικός ψηφιακός βοηθός για μια ασφαλιστική εταιρεία.\n",
    "\n",
    "Ο πελάτης λέει: {query}\n",
    "\n",
    "Η απάντησή σου:\n",
    "\"\"\"\n",
    "\n",
    "extract_template = \"\"\"\n",
    "Εξήγαγε τις εξής πληροφορίες από το μήνυμα του πελάτη:\n",
    "\n",
    "- Ονοματεπώνυμο\n",
    "- Ημερομηνία γέννησης\n",
    "- Τύπος ασφάλισης\n",
    "- Περιγραφή προβλήματος\n",
    "- Αριθμός συμβολαίου\n",
    "\n",
    "Απάντησε μόνο με ένα έγκυρο αντικείμενο JSON:\n",
    "{{\n",
    "  \"name\": \"...\",\n",
    "  \"dob\": \"...\",\n",
    "  \"insurance_type\": \"...\",\n",
    "  \"issue_description\": \"...\",\n",
    "  \"policy_number\": \"...\"\n",
    "}}\n",
    "\n",
    "Μήνυμα πελάτη: {query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:35:18.227468Z",
     "iopub.status.busy": "2025-05-24T11:35:18.227032Z",
     "iopub.status.idle": "2025-05-24T11:35:38.315363Z",
     "shell.execute_reply": "2025-05-24T11:35:38.314637Z",
     "shell.execute_reply.started": "2025-05-24T11:35:18.227441Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Εξήγαγε τις εξής πληροφορίες από το μήνυμα του πελάτη:\n",
      "\n",
      "- Ονοματεπώνυμο\n",
      "- Ημερομηνία γέννησης\n",
      "- Τύπος ασφάλισης\n",
      "- Περιγραφή προβλήματος\n",
      "- Αριθμός συμβολαίου\n",
      "\n",
      "Απάντησε μόνο με ένα έγκυρο αντικείμενο JSON:\n",
      "{\n",
      "  \"name\": \"...\",\n",
      "  \"dob\": \"...\",\n",
      "  \"insurance_type\": \"...\",\n",
      "  \"issue_description\": \"...\",\n",
      "  \"policy_number\": \"...\"\n",
      "}\n",
      "\n",
      "Μήνυμα πελάτη: Καλησπέρα, ονομάζομαι Ιωάννης Παπαδόπουλος, γεννήθηκα στις 15 Μαρτίου 1980. Το αμαξι μου χαλασε στην οδο Παπαδακη 68 μπορειτε να στειλετε την βοήθεια δρόμου\n",
      "\n",
      "Σύμβουλος: Σας προσεκτάμε να προσθέσθει μια βοήθεια δρόμου στην οδό Παπαδακη 68, όπως η βοήθεια δρόμου στην οδό Δελφίνη 74.\n",
      "🤖 Assistant:\n",
      " Είσαι ένας βοηθητικός και ευγενικός ψηφιακός βοηθός για μια ασφαλιστική εταιρεία.\n",
      "\n",
      "Ο πελάτης λέει: Καλησπέρα, ονομάζομαι Ιωάννης Παπαδόπουλος, γεννήθηκα στις 15 Μαρτίου 1980. Το αμαξι μου χαλασε στην οδο Παπαδακη 68 μπορειτε να στειλετε την βοήθεια δρόμου\n",
      "\n",
      "Η απάντησή σου:\n",
      "\n",
      "Ωρα παρακληθώ, ποτέ θα περνά σας ένα βοηθή και ευγενικό ψηφιακό βοηθό! Σας προσωπικά προσέγγῳ ότι η βοηθή είναι η πρωτογενή σας, και ότι η ευγενικότητα είναι η πρωτογενή σας που είναι η πρωτογενή σας. Σας προσωπικά προσέγγῳ ότι η βοηθή και η ευγενικότητα είναι πρωτογενίδα που είναι η πρωτογενή\n",
      "\n",
      "📄 Extracted Info:\n",
      " Εξήγαγε τις εξής πληροφορίες από το μήνυμα του πελάτη:\n",
      "\n",
      "- Ονοματεπώνυμο\n",
      "- Ημερομηνία γέννησης\n",
      "- Τύπος ασφάλισης\n",
      "- Περιγραφή προβλήματος\n",
      "- Αριθμός συμβολαίου\n",
      "\n",
      "Απάντησε μόνο με ένα έγκυρο αντικείμενο JSON:\n",
      "{\n",
      "  \"name\": \"...\",\n",
      "  \"dob\": \"...\",\n",
      "  \"insurance_type\": \"...\",\n",
      "  \"issue_description\": \"...\",\n",
      "  \"policy_number\": \"...\"\n",
      "}\n",
      "\n",
      "Μήνυμα πελάτη: Καλησπέρα, ονομάζομαι Ιωάννης Παπαδόπουλος, γεννήθηκα στις 15 Μαρτίου 1980. Το αμαξι μου χαλασε στην οδο Παπαδακη 68 μπορειτε να στειλετε την βοήθεια δρόμου\n",
      "\n",
      "Σύμβουλος: Σας προσεκτάμε να προσθέσθει μια βοήθεια δρόμου στην οδό Παπαδακη 68, όπως η βοήθεια δρόμου στην οδό Δελφίνη 74.\n"
     ]
    }
   ],
   "source": [
    "insurance_chat(\"Καλησπέρα, ονομάζομαι Ιωάννης Παπαδόπουλος, γεννήθηκα στις 15 Μαρτίου 1980. Το αμαξι μου χαλασε στην οδο Παπαδακη 68 μπορειτε να στειλετε την βοήθεια δρόμου\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:01:10.956637Z",
     "iopub.status.busy": "2025-05-24T11:01:10.956214Z",
     "iopub.status.idle": "2025-05-24T11:01:25.461466Z",
     "shell.execute_reply": "2025-05-24T11:01:25.458150Z",
     "shell.execute_reply.started": "2025-05-24T11:01:10.956600Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-community --quiet\n",
    "# ✅ 1. Install necessary packages (no need for langchain-together anymore)\n",
    "!pip install -U transformers accelerate langchain huggingface_hub sentencepiece --quiet\n",
    "\n",
    "# ✅ 2. Imports\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:02:14.189276Z",
     "iopub.status.busy": "2025-05-24T11:02:14.188835Z",
     "iopub.status.idle": "2025-05-24T11:02:14.661877Z",
     "shell.execute_reply": "2025-05-24T11:02:14.659289Z",
     "shell.execute_reply.started": "2025-05-24T11:02:14.189243Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c988e7aabace48ec84687fd08fc8e21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.llama.tokenization_llama_fast because of the following error (look up to see its traceback):\ncannot import name 'requires' from 'transformers.utils.import_utils' (/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1966\u001b[0m                         \u001b[0mmissing_backends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1967\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1968\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/tokenization_llama_fast.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_sentencepiece_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_llama\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlamaTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/tokenization_llama.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequires\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'requires' from 'transformers.utils.import_utils' (/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/775356579.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ✅ 4. Load tokenizer and model (auto-detects GPU if available)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m model = AutoModelForCausalLM.from_pretrained(\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m                 \u001b[0mtokenizer_auto_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"AutoTokenizer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_auto_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m         has_local_code = type(config) in TOKENIZER_MAPPING or (\n\u001b[1;32m    979\u001b[0m             \u001b[0mconfig_tokenizer_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mtokenizer_class_from_name\u001b[0;34m(class_name)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizers\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTOKENIZER_MAPPING_NAMES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0mmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_type_to_module_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{module_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transformers.models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1953\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\">\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m                             \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m                             \u001b[0mcallable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_satisfied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_backends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.llama.tokenization_llama_fast because of the following error (look up to see its traceback):\ncannot import name 'requires' from 'transformers.utils.import_utils' (/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py)"
     ]
    }
   ],
   "source": [
    "# ✅ 3. Choose DeepSeek model (no gated access)\n",
    "model_id = \"deepseek-ai/DeepSeek-R1\"  # You can change to deepseek-coder-* if desired\n",
    "\n",
    "# ✅ 4. Load tokenizer and model (auto-detects GPU if available)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# ✅ 5. Build a pipeline for inference\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=250,\n",
    "    temperature=0.0,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "# ✅ 6. Wrap in LangChain LLM interface\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# ✅ 7. Create prompt template\n",
    "template = \"\"\"You are an AI assistant for an insurance company. Extract relevant information and respond accurately.\n",
    "Question: {query}\"\"\"\n",
    "# ✅ Install latest dependencies\n",
    "!pip install -U transformers accelerate sentencepiece bitsandbytes langchain langchain-community --quiet\n",
    "\n",
    "# ✅ Imports\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "import torch\n",
    "\n",
    "# ✅ DeepSeek-R1 model\n",
    "model_id = \"deepseek-ai/DeepSeek-R1\"\n",
    "\n",
    "# ✅ Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# ✅ Hugging Face pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=250,\n",
    "    temperature=0.0,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "# ✅ LangChain wrapper\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# ✅ Prompt template\n",
    "template = \"\"\"You are an AI assistant for an insurance company. Extract relevant information and respond accurately.\n",
    "Question: {query}\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ✅ Chain\n",
    "chain = prompt | llm\n",
    "\n",
    "# ✅ Test\n",
    "response = chain.invoke({\"query\": \"Hi, my name is John. I had a car accident in New York on May 10th.\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:05:50.312783Z",
     "iopub.status.busy": "2025-05-24T11:05:50.312264Z",
     "iopub.status.idle": "2025-05-24T11:06:12.599656Z",
     "shell.execute_reply": "2025-05-24T11:06:12.598359Z",
     "shell.execute_reply.started": "2025-05-24T11:05:50.312753Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.52.3\n",
      "Uninstalling transformers-4.52.3:\n",
      "  Successfully uninstalled transformers-4.52.3\n",
      "Found existing installation: tokenizers 0.21.1\n",
      "Uninstalling tokenizers-0.21.1:\n",
      "  Successfully uninstalled tokenizers-0.21.1\n",
      "Found existing installation: huggingface-hub 0.32.0\n",
      "Uninstalling huggingface-hub-0.32.0:\n",
      "  Successfully uninstalled huggingface-hub-0.32.0\n",
      "Found existing installation: accelerate 1.7.0\n",
      "Uninstalling accelerate-1.7.0:\n",
      "  Successfully uninstalled accelerate-1.7.0\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 🚫 Uninstall broken versions\n",
    "!pip uninstall -y transformers\n",
    "!pip uninstall -y tokenizers\n",
    "!pip uninstall -y huggingface_hub\n",
    "!pip uninstall -y accelerate\n",
    "\n",
    "# ✅ Reinstall cleanly with versions compatible with DeepSeek\n",
    "!pip install -U \"transformers==4.40.1\" \"accelerate>=0.28.0\" sentencepiece bitsandbytes --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:07:50.728304Z",
     "iopub.status.busy": "2025-05-24T11:07:50.727846Z",
     "iopub.status.idle": "2025-05-24T11:08:31.775954Z",
     "shell.execute_reply": "2025-05-24T11:08:31.774715Z",
     "shell.execute_reply.started": "2025-05-24T11:07:50.728263Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.40.1\n",
      "Uninstalling transformers-4.40.1:\n",
      "  Successfully uninstalled transformers-4.40.1\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Uninstall the current one\n",
    "!pip uninstall -y transformers\n",
    "\n",
    "# Install the latest bleeding-edge transformers from GitHub (with deepseek_v3 support)\n",
    "!pip install git+https://github.com/huggingface/transformers.git --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:08:49.095462Z",
     "iopub.status.busy": "2025-05-24T11:08:49.095110Z",
     "iopub.status.idle": "2025-05-24T11:08:49.101776Z",
     "shell.execute_reply": "2025-05-24T11:08:49.100397Z",
     "shell.execute_reply.started": "2025-05-24T11:08:49.095430Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:09:01.924080Z",
     "iopub.status.busy": "2025-05-24T11:09:01.923635Z",
     "iopub.status.idle": "2025-05-24T11:09:03.206693Z",
     "shell.execute_reply": "2025-05-24T11:09:03.205238Z",
     "shell.execute_reply.started": "2025-05-24T11:09:01.924025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.deepseek_v3.configuration_deepseek_v3 because of the following error (look up to see its traceback):\nNo module named 'transformers.models.deepseek_v3.configuration_deepseek_v3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1966\u001b[0m                         \u001b[0mmissing_backends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1967\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1968\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers.models.deepseek_v3.configuration_deepseek_v3'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/3901678933.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quantization_config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         >>> config, unused_kwargs = AutoConfig.from_pretrained(\n\u001b[1;32m   1130\u001b[0m         \u001b[0;34m...\u001b[0m     \u001b[0;34m\"google-bert/bert-base-uncased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfoo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         ... )\n\u001b[0m\u001b[1;32m   1132\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDEPRECATED_MODELS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"deprecated.{key}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1953\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\">\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m                             \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m                             \u001b[0mcallable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_satisfied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_backends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.deepseek_v3.configuration_deepseek_v3 because of the following error (look up to see its traceback):\nNo module named 'transformers.models.deepseek_v3.configuration_deepseek_v3'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import torch\n",
    "\n",
    "model_id = \"deepseek-ai/DeepSeek-R1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=250,\n",
    "    temperature=0.0,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "template = \"\"\"You are an AI assistant for an insurance company. Extract relevant information and respond accurately.\n",
    "Question: {query}\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"query\": \"Hi, my name is John. I had a car accident in New York on May 10th.\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:11:17.851002Z",
     "iopub.status.busy": "2025-05-24T11:11:17.850678Z",
     "iopub.status.idle": "2025-05-24T11:12:02.518579Z",
     "shell.execute_reply": "2025-05-24T11:12:02.517150Z",
     "shell.execute_reply.started": "2025-05-24T11:11:17.850975Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.53.0.dev0\n",
      "Uninstalling transformers-4.53.0.dev0:\n",
      "  Successfully uninstalled transformers-4.53.0.dev0\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-2n847kjt\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-2n847kjt\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 31f8a0fe8a7e2db1ee30bf32ed5976cd11f3283c\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (0.32.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.0.dev0) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.0.dev0) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.0.dev0) (1.1.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.53.0.dev0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.53.0.dev0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.53.0.dev0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.53.0.dev0) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.53.0.dev0) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.53.0.dev0) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.0.dev0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.0.dev0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.0.dev0) (2025.4.26)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.53.0.dev0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.53.0.dev0) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.53.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.53.0.dev0) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.53.0.dev0) (2024.2.0)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for transformers: filename=transformers-4.53.0.dev0-py3-none-any.whl size=11365971 sha256=c870c63c44139f0c56ece15d5d7e97685cfd5a10af64136423fc87702c571432\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-lfz846jg/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.53.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers\n",
    "!pip install git+https://github.com/huggingface/transformers.git --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:13:10.408307Z",
     "iopub.status.busy": "2025-05-24T11:13:10.407962Z",
     "iopub.status.idle": "2025-05-24T11:13:13.421566Z",
     "shell.execute_reply": "2025-05-24T11:13:13.420012Z",
     "shell.execute_reply.started": "2025-05-24T11:13:10.408285Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36afc41f0b494282abfe5e79c9ab06c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c2a9b2e5d24abc89fad6d7dc017087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64470919b47e406b94aa6526d1264129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41557cf3fc2b4df1bc05e926315ac772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.cohere2.configuration_cohere2 because of the following error (look up to see its traceback):\ncannot import name 'layer_type_validation' from 'transformers.configuration_utils' (/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1966\u001b[0m                         \u001b[0mmissing_backends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1967\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1968\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/cohere2/configuration_cohere2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mconfiguration_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_type_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_rope_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrope_config_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'layer_type_validation' from 'transformers.configuration_utils' (/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/748387889.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         trust_remote_code = resolve_trust_remote_code(\n\u001b[0m\u001b[1;32m    549\u001b[0m             \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_local_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_remote_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mkeys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0mmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_type_to_module_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{module_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transformers.models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattribute_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{module_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transformers.models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattribute_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m_load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_attr_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0mmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_type_to_module_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattribute_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;31m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1953\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\">\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m                             \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m                             \u001b[0mcallable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_satisfied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_backends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.cohere2.configuration_cohere2 because of the following error (look up to see its traceback):\ncannot import name 'layer_type_validation' from 'transformers.configuration_utils' (/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=250,\n",
    "    temperature=0.0,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "template = \"\"\"You are an AI assistant for an insurance company. Extract relevant information and respond accurately.\n",
    "Question: {query}\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"query\": \"Hi, my name is John. I had a car accident in New York on May 10th.\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T11:43:09.853102Z",
     "iopub.status.busy": "2025-05-24T11:43:09.852736Z",
     "iopub.status.idle": "2025-05-24T11:46:27.359877Z",
     "shell.execute_reply": "2025-05-24T11:46:27.359349Z",
     "shell.execute_reply.started": "2025-05-24T11:43:09.853083Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5531e399eac346be9b0f8d88b35deb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f7976535184ec688eed4a87fe9d9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868cea9f36524fabbe4379b4a626ab04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7956ea09d34cbd81de2287b1029e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ae84ac2b8844abb3f315d4e010f71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0a76c05b1c4600a44925a971b680fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c97249425c4ab7a885938b3a5a3dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59c00f3053342bf924039bed02ce0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c84515a375248acaea8c48a0b11c78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6158d99369794bd6a6786cfd8a30496f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88804c4609745d995131a305e6ec061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c296b8e0480a48fd80eb4b88b0c23277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "# Replace with any LLaMA model you have access to\n",
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"  # or Llama-3-8b-instruct if available\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True  # Save memory\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=300,\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T12:30:26.218309Z",
     "iopub.status.busy": "2025-05-24T12:30:26.217705Z",
     "iopub.status.idle": "2025-05-24T12:30:26.224912Z",
     "shell.execute_reply": "2025-05-24T12:30:26.224327Z",
     "shell.execute_reply.started": "2025-05-24T12:30:26.218288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "chat_template = \"\"\"\n",
    "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
    "You will be contacted by different types of people when they have a problem with their car.\n",
    "Your first role from the message you receive from the client it to determine in what category they belong into.\n",
    "The four character categories are:\n",
    "1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
    "2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
    "3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
    "4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
    "In the last case your response should be dismissive of our services.\n",
    "In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
    "In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
    "The information we want to hear from the client include\n",
    "- Full Name\n",
    "- Category of Message (as mentioned above)\n",
    "- Location of Accident/Malfunction\n",
    "- What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
    "call accident care to note the accident who was at fault etc.)\n",
    "- In what location should they end up (service center, home etc.)\n",
    "- The exact location of the above location point\n",
    "If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
    "and then try to get as many of the other pieces of information without being overbearing\n",
    "Always be respectful and nice to the client.\n",
    "Be very clear with your answers to the client.\n",
    "The ONLY thing you should return is the message towards the client NOTHING MORE\n",
    "\n",
    "\n",
    "Client says: {query}\n",
    "\n",
    "Your reply:\n",
    "\"\"\"\n",
    "\n",
    "extract_template = \"\"\"\n",
    "Extract the following information from the client message:\n",
    "\n",
    "- Full Name\n",
    "- Category of Message (as mentioned above)\n",
    "- Location of Accident/Malfunction\n",
    "- What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
    "call accident care to note the accident who was at fault etc.)\n",
    "- In what location should they end up (service center, home etc.)\n",
    "- The exact location of the above location point\n",
    "\n",
    "If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
    "\n",
    "Respond only with a valid JSON object:\n",
    "{{\n",
    "  \"name\": \"...\",\n",
    "  \"dob\": \"...\",\n",
    "  \"insurance_type\": \"...\",\n",
    "  \"issue_description\": \"...\",\n",
    "  \"policy_number\": \"...\"\n",
    "}}\n",
    "\n",
    "Client message: {query}\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "def insurance_chat(query):\n",
    "    # Compose prompts\n",
    "    chat_prompt = chat_template.format(query=query)\n",
    "    extract_prompt = extract_template.format(query=query)\n",
    "    # Generate chat response\n",
    "    response_raw = pipe(chat_prompt)[0]['generated_text']\n",
    "    response = response_raw.split(\"Your reply:\")[-1].strip()\n",
    "\n",
    "    # Generate structured extraction\n",
    "    extracted_raw = pipe(extract_prompt)[0]['generated_text'].strip()\n",
    "\n",
    "    # Try to parse the JSON output\n",
    "    try:\n",
    "        extracted_json = json.loads(extracted_raw)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"⚠️ JSON parsing failed. Raw output:\\n\", extracted_raw)\n",
    "        extracted_json = None\n",
    "\n",
    "    # Show results\n",
    "    print(\"🤖 Assistant:\\n\", response)\n",
    "    print(\"\\n📄 Extracted Info:\\n\", extracted_json if extracted_json else extracted_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T12:30:32.750589Z",
     "iopub.status.busy": "2025-05-24T12:30:32.750096Z",
     "iopub.status.idle": "2025-05-24T12:31:03.270817Z",
     "shell.execute_reply": "2025-05-24T12:31:03.270059Z",
     "shell.execute_reply.started": "2025-05-24T12:30:32.750567Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message:\n",
      "\n",
      "- Full Name\n",
      "- Category of Message (as mentioned above)\n",
      "- Location of Accident/Malfunction\n",
      "- What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "call accident care to note the accident who was at fault etc.)\n",
      "- In what location should they end up (service center, home etc.)\n",
      "- The exact location of the above location point\n",
      "\n",
      "If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "\n",
      "Respond only with a valid JSON object:\n",
      "{\n",
      "  \"name\": \"...\",\n",
      "  \"dob\": \"...\",\n",
      "  \"insurance_type\": \"...\",\n",
      "  \"issue_description\": \"...\",\n",
      "  \"policy_number\": \"...\"\n",
      "}\n",
      "\n",
      "Client message: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?\n",
      "I would like to request roadside assistance to have my car fixed as soon as possible.\n",
      "My car's license plate number is ABC123.\n",
      "\n",
      "Response JSON:\n",
      "{\n",
      "  \"name\": \"Alice Chen\",\n",
      "  \"category_of_message\": \"Car Breakdown\",\n",
      "  \"location_of_accident_malfunction\": \"Langston Street\",\n",
      "  \"what_they_want_to_do\": \"Call Roadside Assistance to Fix Car\",\n",
      "  \"in_what_location_should_they_end_up\": \"Service Center\",\n",
      "  \"exact_location_of_service_center\": \"Langston Street\"\n",
      "}\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "def process_client_message(client_message):\n",
      "    # Parse the client message into a dictionary\n",
      "    client_info = {}\n",
      "    lines = client_message.split('\\n')\n",
      "    for line in lines:\n",
      "        if line.strip():\n",
      "            key_value_pair = line.split(': ')\n",
      "            if len(key_value_pair) == 2:\n",
      "                key, value = key_value_pair\n",
      "                client_info[key] = value\n",
      "    \n",
      "    # Extract required information\n",
      "    name = client_info.get('name', 'None')\n",
      "    category_of_message = 'Car Breakdown'\n",
      "    location_of_accident_malfunction = client_info.get('car_broke_down_on', 'None')\n",
      "    what_they_want_to_do = client_info.get('request', 'None')\n",
      "    in_what_location_should_they_end_up = client_info.get('where', 'None')\n",
      "    exact_location_of_service_center = client_info.get('car_b\n",
      "🤖 Assistant:\n",
      " Of course, Alice! If we send someone to assist you, they'll try to diagnose the issue and potentially fix it on the spot. If that's not possible, they might recommend towing it to a service center for further repair. If you'd prefer to have it towed directly, we can arrange that too. Which option sounds more appealing to you?\n",
      "\n",
      "\n",
      "Client says\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message:\n",
      "\n",
      "- Full Name\n",
      "- Category of Message (as mentioned above)\n",
      "- Location of Accident/Malfunction\n",
      "- What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "call accident care to note the accident who was at fault etc.)\n",
      "- In what location should they end up (service center, home etc.)\n",
      "- The exact location of the above location point\n",
      "\n",
      "If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "\n",
      "Respond only with a valid JSON object:\n",
      "{\n",
      "  \"name\": \"...\",\n",
      "  \"dob\": \"...\",\n",
      "  \"insurance_type\": \"...\",\n",
      "  \"issue_description\": \"...\",\n",
      "  \"policy_number\": \"...\"\n",
      "}\n",
      "\n",
      "Client message: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?\n",
      "I would like to request roadside assistance to have my car fixed as soon as possible.\n",
      "My car's license plate number is ABC123.\n",
      "\n",
      "Response JSON:\n",
      "{\n",
      "  \"name\": \"Alice Chen\",\n",
      "  \"category_of_message\": \"Car Breakdown\",\n",
      "  \"location_of_accident_malfunction\": \"Langston Street\",\n",
      "  \"what_they_want_to_do\": \"Call Roadside Assistance to Fix Car\",\n",
      "  \"in_what_location_should_they_end_up\": \"Service Center\",\n",
      "  \"exact_location_of_service_center\": \"Langston Street\"\n",
      "}\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "def process_client_message(client_message):\n",
      "    # Parse the client message into a dictionary\n",
      "    client_info = {}\n",
      "    lines = client_message.split('\\n')\n",
      "    for line in lines:\n",
      "        if line.strip():\n",
      "            key_value_pair = line.split(': ')\n",
      "            if len(key_value_pair) == 2:\n",
      "                key, value = key_value_pair\n",
      "                client_info[key] = value\n",
      "    \n",
      "    # Extract required information\n",
      "    name = client_info.get('name', 'None')\n",
      "    category_of_message = 'Car Breakdown'\n",
      "    location_of_accident_malfunction = client_info.get('car_broke_down_on', 'None')\n",
      "    what_they_want_to_do = client_info.get('request', 'None')\n",
      "    in_what_location_should_they_end_up = client_info.get('where', 'None')\n",
      "    exact_location_of_service_center = client_info.get('car_b\n"
     ]
    }
   ],
   "source": [
    "insurance_chat(\"Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T12:38:13.257135Z",
     "iopub.status.busy": "2025-05-24T12:38:13.256729Z",
     "iopub.status.idle": "2025-05-24T12:38:43.711517Z",
     "shell.execute_reply": "2025-05-24T12:38:43.710696Z",
     "shell.execute_reply.started": "2025-05-24T12:38:13.257113Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message:\n",
      "\n",
      "- Full Name\n",
      "- Category of Message (as mentioned above)\n",
      "- Location of Accident/Malfunction\n",
      "- What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "call accident care to note the accident who was at fault etc.)\n",
      "- In what location should they end up (service center, home etc.)\n",
      "- The exact location of the above location point\n",
      "\n",
      "If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "\n",
      "Respond only with a valid JSON object:\n",
      "{\n",
      "  \"name\": \"...\",\n",
      "  \"dob\": \"...\",\n",
      "  \"insurance_type\": \"...\",\n",
      "  \"issue_description\": \"...\",\n",
      "  \"policy_number\": \"...\"\n",
      "}\n",
      "\n",
      "Client message: Hello my name is John Doe and I have been in an accident. There was a car coming the other way and we just collided head-on there are no serious injuries but we need you to come quickly!\n",
      "Location of accident: 123 Main St, Anytown USA\n",
      "Category of Message: Car Accident\n",
      "What they want to do: Call Road Assistance to come fix the car\n",
      "In what location should they end up: Service Center\n",
      "The exact location of the above location point: 456 Elm St, Anytown USA\n",
      "\n",
      "Response JSON object:\n",
      "{\n",
      "  \"name\": \"John Doe\",\n",
      "  \"category_of_message\": \"Car Accident\",\n",
      "  \"location_of_accident\": \"123 Main St, Anytown USA\",\n",
      "  \"what_they_want_to_do\": \"Call Road Assistance to come fix the car\",\n",
      "  \"where_they_should_end_up\": \"Service Center\",\n",
      "  \"exact_location_where_they_should_end_up\": \"456 Elm St, Anytown USA\"\n",
      "} \n",
      "\n",
      "```python\n",
      "def process_client_message(client_message):\n",
      "    \"\"\"\n",
      "    Process the client message and extract relevant information.\n",
      "\n",
      "    Args:\n",
      "        client_message (str): The client's message.\n",
      "\n",
      "    Returns:\n",
      "        dict: A dictionary containing the extracted information.\n",
      "    \"\"\"\n",
      "\n",
      "    # Split the client message into lines for easier processing\n",
      "    lines = client_message.split('\\n')\n",
      "\n",
      "    # Initialize the response dictionary\n",
      "    response = {\n",
      "        \"name\": None,\n",
      "        \"category_of_message\": None,\n",
      "        \"location_of_accident\": None,\n",
      "        \"what_they_want_to_do\": None,\n",
      "        \"where_they_should_end_up\": None,\n",
      "        \"exact_location_where_they_should_end_up\": None\n",
      "🤖 Assistant:\n",
      " Sorry to hear that your cat is stuck in a tree, but unfortunately, we don't provide services for animal rescues. Our services are\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message:\n",
      "\n",
      "- Full Name\n",
      "- Category of Message (as mentioned above)\n",
      "- Location of Accident/Malfunction\n",
      "- What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "call accident care to note the accident who was at fault etc.)\n",
      "- In what location should they end up (service center, home etc.)\n",
      "- The exact location of the above location point\n",
      "\n",
      "If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "\n",
      "Respond only with a valid JSON object:\n",
      "{\n",
      "  \"name\": \"...\",\n",
      "  \"dob\": \"...\",\n",
      "  \"insurance_type\": \"...\",\n",
      "  \"issue_description\": \"...\",\n",
      "  \"policy_number\": \"...\"\n",
      "}\n",
      "\n",
      "Client message: Hello my name is John Doe and I have been in an accident. There was a car coming the other way and we just collided head-on there are no serious injuries but we need you to come quickly!\n",
      "Location of accident: 123 Main St, Anytown USA\n",
      "Category of Message: Car Accident\n",
      "What they want to do: Call Road Assistance to come fix the car\n",
      "In what location should they end up: Service Center\n",
      "The exact location of the above location point: 456 Elm St, Anytown USA\n",
      "\n",
      "Response JSON object:\n",
      "{\n",
      "  \"name\": \"John Doe\",\n",
      "  \"category_of_message\": \"Car Accident\",\n",
      "  \"location_of_accident\": \"123 Main St, Anytown USA\",\n",
      "  \"what_they_want_to_do\": \"Call Road Assistance to come fix the car\",\n",
      "  \"where_they_should_end_up\": \"Service Center\",\n",
      "  \"exact_location_where_they_should_end_up\": \"456 Elm St, Anytown USA\"\n",
      "} \n",
      "\n",
      "```python\n",
      "def process_client_message(client_message):\n",
      "    \"\"\"\n",
      "    Process the client message and extract relevant information.\n",
      "\n",
      "    Args:\n",
      "        client_message (str): The client's message.\n",
      "\n",
      "    Returns:\n",
      "        dict: A dictionary containing the extracted information.\n",
      "    \"\"\"\n",
      "\n",
      "    # Split the client message into lines for easier processing\n",
      "    lines = client_message.split('\\n')\n",
      "\n",
      "    # Initialize the response dictionary\n",
      "    response = {\n",
      "        \"name\": None,\n",
      "        \"category_of_message\": None,\n",
      "        \"location_of_accident\": None,\n",
      "        \"what_they_want_to_do\": None,\n",
      "        \"where_they_should_end_up\": None,\n",
      "        \"exact_location_where_they_should_end_up\": None\n"
     ]
    }
   ],
   "source": [
    "insurance_chat(\"Hello my name is John Doe and I have been in an accident. There was a car coming the other way and we just collided head-on there are no serious injuries but we need you to come quickly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T12:52:46.880531Z",
     "iopub.status.busy": "2025-05-24T12:52:46.880261Z",
     "iopub.status.idle": "2025-05-24T12:52:46.885560Z",
     "shell.execute_reply": "2025-05-24T12:52:46.884785Z",
     "shell.execute_reply.started": "2025-05-24T12:52:46.880509Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Consider adding these to your pipeline:\n",
    "\n",
    "# Better error handling for JSON extraction\n",
    "def safe_json_extraction(text):\n",
    "    start = text.find('{')\n",
    "    end = text.rfind('}') + 1\n",
    "    if start == -1 or end == 0:\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(text[start:end])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Conversation summary for long chats\n",
    "def summarize_conversation(history):\n",
    "    summary_prompt = f\"\"\"Summarize this insurance conversation:\n",
    "    {\" \".join(history)}\n",
    "    \n",
    "    Focus on:\n",
    "    - Client's main issue\n",
    "    - Information gathered\n",
    "    - Next steps\n",
    "    \n",
    "    Summary:\"\"\"\n",
    "    return pipe(summary_prompt)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:48:03.798617Z",
     "iopub.status.busy": "2025-05-24T13:48:03.798319Z",
     "iopub.status.idle": "2025-05-24T13:48:03.807886Z",
     "shell.execute_reply": "2025-05-24T13:48:03.807298Z",
     "shell.execute_reply.started": "2025-05-24T13:48:03.798594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Add this at the top of your script\n",
    "conversation_histories = defaultdict(list)\n",
    "\n",
    "def update_chat_template(history):\n",
    "    system_prompt = \"\"\"\n",
    "                You are an AI assistant for the insurance company named Greek Insurance Company.\n",
    "                You will be contacted by different types of people when they have a problem with their car.\n",
    "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
    "                The four character categories are:\n",
    "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
    "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
    "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
    "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
    "                In the last case your response should be dismissive of our services.\n",
    "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
    "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
    "                The information we want to hear from the client include\n",
    "                - Full Name\n",
    "                - Category of Message (as mentioned above)\n",
    "                - Location of Accident/Malfunction\n",
    "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
    "                call accident care to note the accident who was at fault etc.)\n",
    "                - In what location should they end up (service center, home etc.) \n",
    "                - The exact location of the above location point\n",
    "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
    "                and then try to get as many of the other pieces of information without being overbearing\n",
    "                Always be respectful and nice to the client.\n",
    "                Be very clear with your answers to the client.\n",
    "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
    "                Don't repeat to the client the info they gave you in previous message\n",
    "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
    "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
    "                Always care about their safety\n",
    "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
    "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
    "                \n",
    "                \n",
    "                Client says: {query}\n",
    "                \n",
    "                Your reply:\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    for i, (user_msg, assistant_msg) in enumerate(zip(history[::2], history[1::2])):\n",
    "        messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "    if len(history) % 2 == 1:\n",
    "        messages.append({\"role\": \"user\", \"content\": history[-1]})\n",
    "    \n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "def insurance_chat(query, user_id=\"default\"):\n",
    "    # Get conversation history\n",
    "    history = conversation_histories[user_id]\n",
    "    history.append(query)\n",
    "    \n",
    "    # Generate prompt with history\n",
    "    prompt = update_chat_template(history)\n",
    "    \n",
    "    # Generate response\n",
    "    response_raw = pipe(prompt)[0]['generated_text']\n",
    "    \n",
    "    # Extract just the new response\n",
    "    response = response_raw.split(history[-1])[-1].strip()\n",
    "    \n",
    "    # Update history with assistant response\n",
    "    history.append(response)\n",
    "    \n",
    "    # Generate structured extraction (modified to use full conversation)\n",
    "    extract_prompt = f\"\"\"\n",
    "        Extract the following information from the client message history:\n",
    "        \n",
    "        - Full Name\n",
    "        - Category of Message (as mentioned above)\n",
    "        - Location of Accident/Malfunction\n",
    "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
    "        call accident care to note the accident who was at fault etc.)\n",
    "        - In what location should they end up (service center, home etc.)\n",
    "        - The exact location of the above location point\n",
    "    \n",
    "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
    "        \n",
    "        Respond only with a valid JSON object:\n",
    "        {{\n",
    "          \"name\": \"...\",\n",
    "          \"dob\": \"...\",\n",
    "          \"insurance_type\": \"...\",\n",
    "          \"issue_description\": \"...\",\n",
    "          \"policy_number\": \"...\"\n",
    "        }}\n",
    "    \n",
    "        Client message: {query}\n",
    "        The history is the following: {\" \".join(history)}\"\"\"\n",
    "    \n",
    "    extracted_raw = pipe(extract_prompt)[0]['generated_text'].strip()\n",
    "    \n",
    "    try:\n",
    "        extracted_json = json.loads(extracted_raw)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"⚠️ JSON parsing failed. Raw output:\\n\", extracted_raw)\n",
    "        extracted_json = None\n",
    "\n",
    "    print(\"🤖 Assistant:\\n\", response)\n",
    "    print(\"\\n📄 Extracted Info:\\n\", extracted_json if extracted_json else extracted_raw)\n",
    "    \n",
    "    return response, extracted_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:48:08.460711Z",
     "iopub.status.busy": "2025-05-24T13:48:08.460084Z",
     "iopub.status.idle": "2025-05-24T13:48:21.290014Z",
     "shell.execute_reply": "2025-05-24T13:48:21.289271Z",
     "shell.execute_reply.started": "2025-05-24T13:48:08.460690Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - In what location should they end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"dob\": \"...\",\n",
      "          \"insurance_type\": \"...\",\n",
      "          \"issue_description\": \"...\",\n",
      "          \"policy_number\": \"...\"\n",
      "        }\n",
      "    \n",
      "        Client message: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down. Can you tell me where on Langston Street you're located, please? Is it near any landmarks or intersections that might help me narrow down the location?\n",
      "\n",
      "Also, would you like Road Assistance to send someone to help you fix your car, or would you prefer to have it towed to a service center? And if so, which service center would you like it to be taken to?\n",
      "\n",
      "Let me know and I'll do my best to assist you further.\n",
      "\n",
      "Here's the extracted information in JSON format:\n",
      "\n",
      "{\n",
      "  \"name\": \"Alice Chen\",\n",
      "  \"category_of_message\": \"Car Breakdown\",\n",
      "  \"location_of_accident_malfunction\": \"Langston Street\",\n",
      "  \"what_they_want_to_do\": \"Road Assistance to fix the car or Tow Truck to take it away\",\n",
      "  \"in_what_location_should_they_end_up\": \"Service Center\",\n",
      "  \"exact_location_of_above_location_point\": \"None\"\n",
      "}\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down. Can you tell me where on Langston Street you're located, please? Is it near any landmarks or intersections that might help me narrow down the location?\n",
      "\n",
      "Also, would you like Road Assistance to send someone to help you fix your car, or would you prefer to have it towed to a service center?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - In what location should they end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"dob\": \"...\",\n",
      "          \"insurance_type\": \"...\",\n",
      "          \"issue_description\": \"...\",\n",
      "          \"policy_number\": \"...\"\n",
      "        }\n",
      "    \n",
      "        Client message: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down. Can you tell me where on Langston Street you're located, please? Is it near any landmarks or intersections that might help me narrow down the location?\n",
      "\n",
      "Also, would you like Road Assistance to send someone to help you fix your car, or would you prefer to have it towed to a service center? And if so, which service center would you like it to be taken to?\n",
      "\n",
      "Let me know and I'll do my best to assist you further.\n",
      "\n",
      "Here's the extracted information in JSON format:\n",
      "\n",
      "{\n",
      "  \"name\": \"Alice Chen\",\n",
      "  \"category_of_message\": \"Car Breakdown\",\n",
      "  \"location_of_accident_malfunction\": \"Langston Street\",\n",
      "  \"what_they_want_to_do\": \"Road Assistance to fix the car or Tow Truck to take it away\",\n",
      "  \"in_what_location_should_they_end_up\": \"Service Center\",\n",
      "  \"exact_location_of_above_location_point\": \"None\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"<|eot_id|>assistant\\n\\nHello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down. Can you tell me where on Langston Street you're located, please? Is it near any landmarks or intersections that might help me narrow down the location?\\n\\nAlso, would you like Road Assistance to send someone to help you fix your car, or would you prefer to have it towed to a service center?\",\n",
       " None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_chat(\"Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:49:25.424985Z",
     "iopub.status.busy": "2025-05-24T13:49:25.424272Z",
     "iopub.status.idle": "2025-05-24T13:49:40.324290Z",
     "shell.execute_reply": "2025-05-24T13:49:40.323673Z",
     "shell.execute_reply.started": "2025-05-24T13:49:25.424955Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - In what location should they end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"dob\": \"...\",\n",
      "          \"insurance_type\": \"...\",\n",
      "          \"issue_description\": \"...\",\n",
      "          \"policy_number\": \"...\"\n",
      "        }\n",
      "    \n",
      "        Client message: Yes I am currectly on Georgian Street 25 and can you please send road assistance immediately. I have to take the car to the service center!! I don't know what happened exactly but it seemed to put our some kind of screetching noise before stopping\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down. Can you tell me where on Langston Street you're located, please? Is it near any landmarks or intersections that might help me narrow down the location?\n",
      "\n",
      "Also, would you like Road Assistance to send someone to help you fix your car, or would you prefer to have it towed to a service center? Yes I am currectly on Georgian Street 25 and can you please send road assistance immediately. I have to take the car to the service center!! I don't know what happened exactly but it seemed to put our some kind of screetching noise before stopping <|eot_id|>assistant\n",
      "\n",
      "Alice, thank you for providing the new location. I've noted that you're currently on Georgian Street 25.\n",
      "\n",
      "I'd be happy to send Road Assistance to help you. They'll arrive shortly to assist you. As for the issue with your car making a screeching noise before stopping, I'm going to take a guess that it might be related to a potential brake problem. However, our technician will assess this further once they arrive.\n",
      "\n",
      "To confirm, you'd like to have your car taken to our Service Center, correct? And would you like it to be dropped off at the main entrance or would you prefer a specific bay number? \n",
      "\n",
      "Here's the extracted information in JSON format:\n",
      "\n",
      "{\n",
      "  \"name\": \"Alice Chen\",\n",
      "  \"category_of_message\": \"Car Breakdown\",\n",
      "  \"location_of_accident_malfunction\": \"Langston Street\",\n",
      "  \"what_they_want_to_do\": \"Call Road Assistance to Fix Car\",\n",
      "  \"in_what_location_should_they_end_up\": \"Service Center\",\n",
      "  \"exact_location_of_above_location_point\": \"Georgian Street 25\"\n",
      "}\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "Alice, thank you for providing the new location. I've noted that you're currently on Georgian Street 25.\n",
      "\n",
      "I'd be happy to send Road Assistance to help you. They'll arrive shortly to assist you. As for the issue with your car making a screeching noise before stopping, I'm going to take a guess that it might be related to a potential brake problem. However, our technician will assess this further once they arrive.\n",
      "\n",
      "To confirm, you'd like to have your car taken to our Service Center, correct? And would you like it to be dropped off at the main entrance or would you prefer a specific bay number?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - In what location should they end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"dob\": \"...\",\n",
      "          \"insurance_type\": \"...\",\n",
      "          \"issue_description\": \"...\",\n",
      "          \"policy_number\": \"...\"\n",
      "        }\n",
      "    \n",
      "        Client message: Yes I am currectly on Georgian Street 25 and can you please send road assistance immediately. I have to take the car to the service center!! I don't know what happened exactly but it seemed to put our some kind of screetching noise before stopping\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down. Can you tell me where on Langston Street you're located, please? Is it near any landmarks or intersections that might help me narrow down the location?\n",
      "\n",
      "Also, would you like Road Assistance to send someone to help you fix your car, or would you prefer to have it towed to a service center? Yes I am currectly on Georgian Street 25 and can you please send road assistance immediately. I have to take the car to the service center!! I don't know what happened exactly but it seemed to put our some kind of screetching noise before stopping <|eot_id|>assistant\n",
      "\n",
      "Alice, thank you for providing the new location. I've noted that you're currently on Georgian Street 25.\n",
      "\n",
      "I'd be happy to send Road Assistance to help you. They'll arrive shortly to assist you. As for the issue with your car making a screeching noise before stopping, I'm going to take a guess that it might be related to a potential brake problem. However, our technician will assess this further once they arrive.\n",
      "\n",
      "To confirm, you'd like to have your car taken to our Service Center, correct? And would you like it to be dropped off at the main entrance or would you prefer a specific bay number? \n",
      "\n",
      "Here's the extracted information in JSON format:\n",
      "\n",
      "{\n",
      "  \"name\": \"Alice Chen\",\n",
      "  \"category_of_message\": \"Car Breakdown\",\n",
      "  \"location_of_accident_malfunction\": \"Langston Street\",\n",
      "  \"what_they_want_to_do\": \"Call Road Assistance to Fix Car\",\n",
      "  \"in_what_location_should_they_end_up\": \"Service Center\",\n",
      "  \"exact_location_of_above_location_point\": \"Georgian Street 25\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"<|eot_id|>assistant\\n\\nAlice, thank you for providing the new location. I've noted that you're currently on Georgian Street 25.\\n\\nI'd be happy to send Road Assistance to help you. They'll arrive shortly to assist you. As for the issue with your car making a screeching noise before stopping, I'm going to take a guess that it might be related to a potential brake problem. However, our technician will assess this further once they arrive.\\n\\nTo confirm, you'd like to have your car taken to our Service Center, correct? And would you like it to be dropped off at the main entrance or would you prefer a specific bay number?\",\n",
       " None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_chat(\"Yes I am currectly on Georgian Street 25 and can you please send road assistance immediately. I have to take the car to the service center!! I don't know what happened exactly but it seemed to put our some kind of screetching noise before stopping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:52:50.208770Z",
     "iopub.status.busy": "2025-05-24T13:52:50.208041Z",
     "iopub.status.idle": "2025-05-24T13:52:59.517225Z",
     "shell.execute_reply": "2025-05-24T13:52:59.516423Z",
     "shell.execute_reply.started": "2025-05-24T13:52:50.208738Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - In what location should they end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"dob\": \"...\",\n",
      "          \"insurance_type\": \"...\",\n",
      "          \"issue_description\": \"...\",\n",
      "          \"policy_number\": \"...\"\n",
      "        }\n",
      "    \n",
      "        Client message: I don't have a problem with the bay number and just teh closest service center is fine\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down. Can you tell me where on Langston Street you're located, please? Is it near any landmarks or intersections that might help me narrow down the location?\n",
      "\n",
      "Also, would you like Road Assistance to send someone to help you fix your car, or would you prefer to have it towed to a service center? Yes I am currectly on Georgian Street 25 and can you please send road assistance immediately. I have to take the car to the service center!! I don't know what happened exactly but it seemed to put our some kind of screetching noise before stopping <|eot_id|>assistant\n",
      "\n",
      "Alice, thank you for providing the new location. I've noted that you're currently on Georgian Street 25.\n",
      "\n",
      "I'd be happy to send Road Assistance to help you. They'll arrive shortly to assist you. As for the issue with your car making a screeching noise before stopping, I'm going to take a guess that it might be related to a potential brake problem. However, our technician will assess this further once they arrive.\n",
      "\n",
      "To confirm, you'd like to have your car taken to our Service Center, correct? And would you like it to be dropped off at the main entrance or would you prefer a specific bay number? I don't have a problem with the bay number and just teh closest service center is fine <|eot_id|>assistant\n",
      "\n",
      "Alice, I've dispatched Road Assistance to your location on Georgian Street 25. They'll arrive shortly to assist you.\n",
      "\n",
      "As for the Service Center, I've noted that you'd like to drop off your vehicle at the nearest one. Our team will meet you there and take care of your car's assessment.\n",
      "\n",
      "Before they arrive, I just want to confirm: Are you safe and comfortable where you are now, or would you like me to arrange for an escort to accompany you to the Service Center?\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "Alice, I've dispatched Road Assistance to your location on Georgian Street 25. They'll arrive shortly to assist you.\n",
      "\n",
      "As for the Service Center, I've noted that you'd like to drop off your vehicle at the nearest one. Our team will meet you there and take care of your car's assessment.\n",
      "\n",
      "Before they arrive, I just want to confirm: Are you safe and comfortable where you are now, or would you like me to arrange for an escort to accompany you to the Service Center?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - In what location should they end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"dob\": \"...\",\n",
      "          \"insurance_type\": \"...\",\n",
      "          \"issue_description\": \"...\",\n",
      "          \"policy_number\": \"...\"\n",
      "        }\n",
      "    \n",
      "        Client message: I don't have a problem with the bay number and just teh closest service center is fine\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down. Can you tell me where on Langston Street you're located, please? Is it near any landmarks or intersections that might help me narrow down the location?\n",
      "\n",
      "Also, would you like Road Assistance to send someone to help you fix your car, or would you prefer to have it towed to a service center? Yes I am currectly on Georgian Street 25 and can you please send road assistance immediately. I have to take the car to the service center!! I don't know what happened exactly but it seemed to put our some kind of screetching noise before stopping <|eot_id|>assistant\n",
      "\n",
      "Alice, thank you for providing the new location. I've noted that you're currently on Georgian Street 25.\n",
      "\n",
      "I'd be happy to send Road Assistance to help you. They'll arrive shortly to assist you. As for the issue with your car making a screeching noise before stopping, I'm going to take a guess that it might be related to a potential brake problem. However, our technician will assess this further once they arrive.\n",
      "\n",
      "To confirm, you'd like to have your car taken to our Service Center, correct? And would you like it to be dropped off at the main entrance or would you prefer a specific bay number? I don't have a problem with the bay number and just teh closest service center is fine <|eot_id|>assistant\n",
      "\n",
      "Alice, I've dispatched Road Assistance to your location on Georgian Street 25. They'll arrive shortly to assist you.\n",
      "\n",
      "As for the Service Center, I've noted that you'd like to drop off your vehicle at the nearest one. Our team will meet you there and take care of your car's assessment.\n",
      "\n",
      "Before they arrive, I just want to confirm: Are you safe and comfortable where you are now, or would you like me to arrange for an escort to accompany you to the Service Center?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"<|eot_id|>assistant\\n\\nAlice, I've dispatched Road Assistance to your location on Georgian Street 25. They'll arrive shortly to assist you.\\n\\nAs for the Service Center, I've noted that you'd like to drop off your vehicle at the nearest one. Our team will meet you there and take care of your car's assessment.\\n\\nBefore they arrive, I just want to confirm: Are you safe and comfortable where you are now, or would you like me to arrange for an escort to accompany you to the Service Center?\",\n",
       " None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_chat(\"I don't have a problem with the bay number and just teh closest service center is fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:53:50.875919Z",
     "iopub.status.busy": "2025-05-24T13:53:50.875198Z",
     "iopub.status.idle": "2025-05-24T13:54:00.939895Z",
     "shell.execute_reply": "2025-05-24T13:54:00.939060Z",
     "shell.execute_reply.started": "2025-05-24T13:53:50.875890Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - In what location should they end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"dob\": \"...\",\n",
      "          \"insurance_type\": \"...\",\n",
      "          \"issue_description\": \"...\",\n",
      "          \"policy_number\": \"...\"\n",
      "        }\n",
      "    \n",
      "        Client message: No no I am fine thank you for the help!\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down. Can you tell me where on Langston Street you're located, please? Is it near any landmarks or intersections that might help me narrow down the location?\n",
      "\n",
      "Also, would you like Road Assistance to send someone to help you fix your car, or would you prefer to have it towed to a service center? Yes I am currectly on Georgian Street 25 and can you please send road assistance immediately. I have to take the car to the service center!! I don't know what happened exactly but it seemed to put our some kind of screetching noise before stopping <|eot_id|>assistant\n",
      "\n",
      "Alice, thank you for providing the new location. I've noted that you're currently on Georgian Street 25.\n",
      "\n",
      "I'd be happy to send Road Assistance to help you. They'll arrive shortly to assist you. As for the issue with your car making a screeching noise before stopping, I'm going to take a guess that it might be related to a potential brake problem. However, our technician will assess this further once they arrive.\n",
      "\n",
      "To confirm, you'd like to have your car taken to our Service Center, correct? And would you like it to be dropped off at the main entrance or would you prefer a specific bay number? I don't have a problem with the bay number and just teh closest service center is fine <|eot_id|>assistant\n",
      "\n",
      "Alice, I've dispatched Road Assistance to your location on Georgian Street 25. They'll arrive shortly to assist you.\n",
      "\n",
      "As for the Service Center, I've noted that you'd like to drop off your vehicle at the nearest one. Our team will meet you there and take care of your car's assessment.\n",
      "\n",
      "Before they arrive, I just want to confirm: Are you safe and comfortable where you are now, or would you like me to arrange for an escort to accompany you to the Service Center? No no I am fine thank you for the help! <|eot_id|>assistant\n",
      "\n",
      "Alice, great, I'm glad to hear that you're okay. Our team from Road Assistance will arrive soon to help you with your car. They'll take good care of you and your vehicle.\n",
      "\n",
      "In the meantime, I've sent you a confirmation text with the details of the assistance, including the estimated arrival time and the Service Center information. Please look out for it.\n",
      "\n",
      "Is there anything else I can assist you with before they arrive? Just wanted to say thanks again for reaching out to us. We're here to help.\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "Alice, great, I'm glad to hear that you're okay. Our team from Road Assistance will arrive soon to help you with your car. They'll take good care of you and your vehicle.\n",
      "\n",
      "In the meantime, I've sent you a confirmation text with the details of the assistance, including the estimated arrival time and the Service Center information. Please look out for it.\n",
      "\n",
      "Is there anything else I can assist you with before they arrive?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - In what location should they end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"dob\": \"...\",\n",
      "          \"insurance_type\": \"...\",\n",
      "          \"issue_description\": \"...\",\n",
      "          \"policy_number\": \"...\"\n",
      "        }\n",
      "    \n",
      "        Client message: No no I am fine thank you for the help!\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down. Can you tell me where on Langston Street you're located, please? Is it near any landmarks or intersections that might help me narrow down the location?\n",
      "\n",
      "Also, would you like Road Assistance to send someone to help you fix your car, or would you prefer to have it towed to a service center? Yes I am currectly on Georgian Street 25 and can you please send road assistance immediately. I have to take the car to the service center!! I don't know what happened exactly but it seemed to put our some kind of screetching noise before stopping <|eot_id|>assistant\n",
      "\n",
      "Alice, thank you for providing the new location. I've noted that you're currently on Georgian Street 25.\n",
      "\n",
      "I'd be happy to send Road Assistance to help you. They'll arrive shortly to assist you. As for the issue with your car making a screeching noise before stopping, I'm going to take a guess that it might be related to a potential brake problem. However, our technician will assess this further once they arrive.\n",
      "\n",
      "To confirm, you'd like to have your car taken to our Service Center, correct? And would you like it to be dropped off at the main entrance or would you prefer a specific bay number? I don't have a problem with the bay number and just teh closest service center is fine <|eot_id|>assistant\n",
      "\n",
      "Alice, I've dispatched Road Assistance to your location on Georgian Street 25. They'll arrive shortly to assist you.\n",
      "\n",
      "As for the Service Center, I've noted that you'd like to drop off your vehicle at the nearest one. Our team will meet you there and take care of your car's assessment.\n",
      "\n",
      "Before they arrive, I just want to confirm: Are you safe and comfortable where you are now, or would you like me to arrange for an escort to accompany you to the Service Center? No no I am fine thank you for the help! <|eot_id|>assistant\n",
      "\n",
      "Alice, great, I'm glad to hear that you're okay. Our team from Road Assistance will arrive soon to help you with your car. They'll take good care of you and your vehicle.\n",
      "\n",
      "In the meantime, I've sent you a confirmation text with the details of the assistance, including the estimated arrival time and the Service Center information. Please look out for it.\n",
      "\n",
      "Is there anything else I can assist you with before they arrive? Just wanted to say thanks again for reaching out to us. We're here to help.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"<|eot_id|>assistant\\n\\nAlice, great, I'm glad to hear that you're okay. Our team from Road Assistance will arrive soon to help you with your car. They'll take good care of you and your vehicle.\\n\\nIn the meantime, I've sent you a confirmation text with the details of the assistance, including the estimated arrival time and the Service Center information. Please look out for it.\\n\\nIs there anything else I can assist you with before they arrive?\",\n",
       " None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_chat(\"No no I am fine thank you for the help!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:55:16.240518Z",
     "iopub.status.busy": "2025-05-24T13:55:16.240008Z",
     "iopub.status.idle": "2025-05-24T13:55:28.973449Z",
     "shell.execute_reply": "2025-05-24T13:55:28.972826Z",
     "shell.execute_reply.started": "2025-05-24T13:55:16.240494Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - In what location should they end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"dob\": \"...\",\n",
      "          \"insurance_type\": \"...\",\n",
      "          \"issue_description\": \"...\",\n",
      "          \"policy_number\": \"...\"\n",
      "        }\n",
      "    \n",
      "        Client message: That's all\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down. Can you tell me where on Langston Street you're located, please? Is it near any landmarks or intersections that might help me narrow down the location?\n",
      "\n",
      "Also, would you like Road Assistance to send someone to help you fix your car, or would you prefer to have it towed to a service center? Yes I am currectly on Georgian Street 25 and can you please send road assistance immediately. I have to take the car to the service center!! I don't know what happened exactly but it seemed to put our some kind of screetching noise before stopping <|eot_id|>assistant\n",
      "\n",
      "Alice, thank you for providing the new location. I've noted that you're currently on Georgian Street 25.\n",
      "\n",
      "I'd be happy to send Road Assistance to help you. They'll arrive shortly to assist you. As for the issue with your car making a screeching noise before stopping, I'm going to take a guess that it might be related to a potential brake problem. However, our technician will assess this further once they arrive.\n",
      "\n",
      "To confirm, you'd like to have your car taken to our Service Center, correct? And would you like it to be dropped off at the main entrance or would you prefer a specific bay number? I don't have a problem with the bay number and just teh closest service center is fine <|eot_id|>assistant\n",
      "\n",
      "Alice, I've dispatched Road Assistance to your location on Georgian Street 25. They'll arrive shortly to assist you.\n",
      "\n",
      "As for the Service Center, I've noted that you'd like to drop off your vehicle at the nearest one. Our team will meet you there and take care of your car's assessment.\n",
      "\n",
      "Before they arrive, I just want to confirm: Are you safe and comfortable where you are now, or would you like me to arrange for an escort to accompany you to the Service Center? No no I am fine thank you for the help! <|eot_id|>assistant\n",
      "\n",
      "Alice, great, I'm glad to hear that you're okay. Our team from Road Assistance will arrive soon to help you with your car. They'll take good care of you and your vehicle.\n",
      "\n",
      "In the meantime, I've sent you a confirmation text with the details of the assistance, including the estimated arrival time and the Service Center information. Please look out for it.\n",
      "\n",
      "Is there anything else I can assist you with before they arrive? That's all <|eot_id|>assistant\n",
      "\n",
      "Alice, you're all set. Help is on the way. Have a safe wait and I'll pass along any additional information to our team. Thank you for reaching out to us, and we hope to see you soon at the Service Center. Goodbye. \n",
      "\n",
      "Here is the extracted information in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"name\": \"Alice Chen\",\n",
      "  \"category_of_message\": \"Car Breakdown\",\n",
      "  \"location_of_accident_malfunction\": \"Langston Street\",\n",
      "  \"what_they_want_to_do\": \"Call Road Assistance to fix the car\",\n",
      "  \"in_what_location_should_they_end_up\": \"Service Center\",\n",
      "  \"exact_location_of_the_above_location_point\": \"Georgian Street 25\"\n",
      "}\n",
      "```\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "Alice, you're all set. Help is on the way. Have a safe wait and I'll pass along any additional information to our team. Thank you for reaching out to us, and we hope to see you soon at the Service Center.\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - In what location should they end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"dob\": \"...\",\n",
      "          \"insurance_type\": \"...\",\n",
      "          \"issue_description\": \"...\",\n",
      "          \"policy_number\": \"...\"\n",
      "        }\n",
      "    \n",
      "        Client message: That's all\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down. Can you tell me where on Langston Street you're located, please? Is it near any landmarks or intersections that might help me narrow down the location?\n",
      "\n",
      "Also, would you like Road Assistance to send someone to help you fix your car, or would you prefer to have it towed to a service center? Yes I am currectly on Georgian Street 25 and can you please send road assistance immediately. I have to take the car to the service center!! I don't know what happened exactly but it seemed to put our some kind of screetching noise before stopping <|eot_id|>assistant\n",
      "\n",
      "Alice, thank you for providing the new location. I've noted that you're currently on Georgian Street 25.\n",
      "\n",
      "I'd be happy to send Road Assistance to help you. They'll arrive shortly to assist you. As for the issue with your car making a screeching noise before stopping, I'm going to take a guess that it might be related to a potential brake problem. However, our technician will assess this further once they arrive.\n",
      "\n",
      "To confirm, you'd like to have your car taken to our Service Center, correct? And would you like it to be dropped off at the main entrance or would you prefer a specific bay number? I don't have a problem with the bay number and just teh closest service center is fine <|eot_id|>assistant\n",
      "\n",
      "Alice, I've dispatched Road Assistance to your location on Georgian Street 25. They'll arrive shortly to assist you.\n",
      "\n",
      "As for the Service Center, I've noted that you'd like to drop off your vehicle at the nearest one. Our team will meet you there and take care of your car's assessment.\n",
      "\n",
      "Before they arrive, I just want to confirm: Are you safe and comfortable where you are now, or would you like me to arrange for an escort to accompany you to the Service Center? No no I am fine thank you for the help! <|eot_id|>assistant\n",
      "\n",
      "Alice, great, I'm glad to hear that you're okay. Our team from Road Assistance will arrive soon to help you with your car. They'll take good care of you and your vehicle.\n",
      "\n",
      "In the meantime, I've sent you a confirmation text with the details of the assistance, including the estimated arrival time and the Service Center information. Please look out for it.\n",
      "\n",
      "Is there anything else I can assist you with before they arrive? That's all <|eot_id|>assistant\n",
      "\n",
      "Alice, you're all set. Help is on the way. Have a safe wait and I'll pass along any additional information to our team. Thank you for reaching out to us, and we hope to see you soon at the Service Center. Goodbye. \n",
      "\n",
      "Here is the extracted information in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"name\": \"Alice Chen\",\n",
      "  \"category_of_message\": \"Car Breakdown\",\n",
      "  \"location_of_accident_malfunction\": \"Langston Street\",\n",
      "  \"what_they_want_to_do\": \"Call Road Assistance to fix the car\",\n",
      "  \"in_what_location_should_they_end_up\": \"Service Center\",\n",
      "  \"exact_location_of_the_above_location_point\": \"Georgian Street 25\"\n",
      "}\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"<|eot_id|>assistant\\n\\nAlice, you're all set. Help is on the way. Have a safe wait and I'll pass along any additional information to our team. Thank you for reaching out to us, and we hope to see you soon at the Service Center.\",\n",
       " None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_chat(\"That's all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate more prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from faker import Faker\n",
    "from transformers import pipeline\n",
    "from typing import List, Dict\n",
    "\n",
    "# Initialize tools\n",
    "fake = Faker()\n",
    "generator = pipeline(\"text-generation\", model=\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "\n",
    "# Load your real conversations (replace with your actual data)\n",
    "real_conversations = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "            {\"role\": \"user\", \"content\": \"I just crashed my car near Syntagma Square!\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I'm sorry to hear about the accident. May I have your full name?\"},\n",
    "            {\"role\": \"user\", \"content\": \"It's Dimitris Ioannou\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Thank you Mr. Ioannou. Were there any other vehicles involved?\"}\n",
    "        ]\n",
    "    },\n",
    "    # Add your other 9 real conversations here\n",
    "]\n",
    "\n",
    "# Define augmentation parameters\n",
    "LOCATIONS = [\"Syntagma Square\", \"Thessaloniki Center\", \"Patras Harbor\", \n",
    "             \"Heraklion Port\", \"Larissa Train Station\", \"Volos Waterfront\"]\n",
    "NAMES = [fake.name() for _ in range(50)]  # Generate 50 Greek names\n",
    "CAR_TYPES = [\"Toyota\", \"Honda\", \"BMW\", \"Mercedes\", \"Fiat\", \"Peugeot\"]\n",
    "ISSUES = [\"engine failure\", \"flat tire\", \"battery dead\", \"accident\", \"overheating\"]\n",
    "\n",
    "def augment_conversation(original: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Create variations of a real conversation\"\"\"\n",
    "    augmented = []\n",
    "    for message in original:\n",
    "        if message[\"role\"] == \"user\":\n",
    "            # Augment user messages\n",
    "            content = message[\"content\"]\n",
    "            content = content.replace(\"Syntagma Square\", random.choice(LOCATIONS))\n",
    "            content = content.replace(\"Dimitris Ioannou\", random.choice(NAMES))\n",
    "            \n",
    "            # Add random car details\n",
    "            if random.random() > 0.7:\n",
    "                car = random.choice(CAR_TYPES)\n",
    "                content = f\"My {car} {random.choice(['had an issue', 'broke down', 'was damaged'])}. {content}\"\n",
    "                \n",
    "            augmented.append({\"role\": \"user\", \"content\": content})\n",
    "        else:\n",
    "            # Keep assistant messages mostly unchanged\n",
    "            augmented.append(message)\n",
    "    return augmented\n",
    "\n",
    "def generate_synthetic_conversation() -> List[Dict]:\n",
    "    \"\"\"Generate completely new synthetic conversation\"\"\"\n",
    "    issue = random.choice(ISSUES)\n",
    "    name = random.choice(NAMES)\n",
    "    location = random.choice(LOCATIONS)\n",
    "    \n",
    "    if \"accident\" in issue:\n",
    "        user_msg = f\"I just had a car accident near {location}! This is {name}.\"\n",
    "        assistant_msgs = [\n",
    "            f\"I'm sorry to hear about the accident Mr. {name.split()[-1]}. Were there any injuries?\",\n",
    "            \"Could you describe what happened?\",\n",
    "            f\"We'll dispatch a team to {location}. Is your car drivable?\"\n",
    "        ]\n",
    "    else:\n",
    "        user_msg = f\"My car has {issue} at {location}. I'm {name}.\"\n",
    "        assistant_msgs = [\n",
    "            f\"I understand you need road assistance Mr. {name.split()[-1]}.\",\n",
    "            f\"Where exactly at {location} are you located?\",\n",
    "            \"Is your car safe to drive or do you need a tow truck?\"\n",
    "        ]\n",
    "    \n",
    "    # Build conversation\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "        {\"role\": \"user\", \"content\": user_msg}\n",
    "    ]\n",
    "    \n",
    "    # Add 2-4 assistant responses\n",
    "    for i in range(random.randint(2, 4)):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_msgs[i % len(assistant_msgs)]})\n",
    "        if i < 3:  # Add user follow-ups\n",
    "            follow_up = generate_user_followup(issue, i)\n",
    "            messages.append({\"role\": \"user\", \"content\": follow_up})\n",
    "    \n",
    "    return messages\n",
    "\n",
    "def generate_user_followup(issue: str, turn: int) -> str:\n",
    "    \"\"\"Generate realistic user follow-up messages\"\"\"\n",
    "    if turn == 0:\n",
    "        return random.choice([\n",
    "            \"Yes, please send help quickly!\",\n",
    "            \"No injuries but the car is badly damaged\",\n",
    "            \"I'm not sure, it just stopped working\"\n",
    "        ])\n",
    "    elif turn == 1:\n",
    "        if \"accident\" in issue:\n",
    "            return random.choice([\n",
    "                \"It was a rear-end collision\",\n",
    "                \"Another car hit me from the side\",\n",
    "                \"I lost control on the wet road\"\n",
    "            ])\n",
    "        else:\n",
    "            return random.choice([\n",
    "                \"Near the main intersection\",\n",
    "                \"In the parking lot\",\n",
    "                \"On the highway shoulder\"\n",
    "            ])\n",
    "    else:\n",
    "        return random.choice([\n",
    "            \"Thank you for your help\",\n",
    "            \"How long will assistance take?\",\n",
    "            \"Should I call the police?\"\n",
    "        ])\n",
    "\n",
    "# Generate synthetic dataset\n",
    "synthetic_data = []\n",
    "\n",
    "# 1. Augment real conversations (5 variations per real conversation)\n",
    "for conv in real_conversations:\n",
    "    for _ in range(5):\n",
    "        synthetic_data.append(augment_conversation(conv))\n",
    "\n",
    "# 2. Generate completely new conversations (90 synthetic examples)\n",
    "for _ in range(90):\n",
    "    synthetic_data.append(generate_synthetic_conversation())\n",
    "\n",
    "# Save the dataset\n",
    "with open(\"synthetic_insurance_conversations.json\", \"w\") as f:\n",
    "    json.dump(synthetic_data, f, indent=2)\n",
    "\n",
    "print(f\"Generated {len(synthetic_data)} synthetic conversations (originally had {len(real_conversations)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load your synthetic data\n",
    "dataset = load_dataset(\"json\", data_files=\"synthetic_insurance_conversations.json\")\n",
    "\n",
    "# Prepare for training (same as before)\n",
    "def format_conversation(example):\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(\n",
    "        example[\"messages\"],\n",
    "        tokenize=False\n",
    "    )\n",
    "    return example\n",
    "\n",
    "formatted_dataset = dataset.map(format_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def refine_with_llm(conversation):\n",
    "    prompt = f\"\"\"Improve this insurance conversation to sound more natural:\n",
    "    {conversation}\n",
    "    \n",
    "    Improved version:\"\"\"\n",
    "    refined = generator(prompt, max_length=1000)[0]['generated_text']\n",
    "    return refined.split(\"Improved version:\")[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Count examples per category\n",
    "category_counts = {\n",
    "    \"accident\": 0,\n",
    "    \"roadside\": 0,\n",
    "    \"pranks\": 0\n",
    "}\n",
    "\n",
    "# Generate until we have enough of each\n",
    "while min(category_counts.values()) < 20:\n",
    "    new_conv = generate_synthetic_conversation()\n",
    "    category = classify_conversation(new_conv)  # Implement this\n",
    "    if category_counts[category] < 20:\n",
    "        synthetic_data.append(new_conv)\n",
    "        category_counts[category] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load a lightweight classifier model (e.g., distilled BERT)\n",
    "model_name = \"distilbert-base-uncased\"  # or \"microsoft/Phi-3-mini-4k-instruct\" for better results\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Create a classification layer on top\n",
    "class ConversationClassifier(torch.nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.classifier = torch.nn.Linear(base_model.config.hidden_size, 4)\n",
    "        \n",
    "    def forward(self, **inputs):\n",
    "        outputs = self.base_model(**inputs)\n",
    "        return self.classifier(outputs.last_hidden_state[:, 0])\n",
    "\n",
    "# Initialize model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "classifier = ConversationClassifier(base_model)\n",
    "\n",
    "# Define your categories\n",
    "categories = [\n",
    "    \"accident_care\",\n",
    "    \"road_assistance\",\n",
    "    \"needs_clarification\",\n",
    "    \"prank_call\"\n",
    "]\n",
    "\n",
    "# Training data preparation (few-shot examples)\n",
    "training_examples = [\n",
    "    (\"I crashed my car near Syntagma Square\", \"accident_care\"),\n",
    "    (\"My engine won't start\", \"road_assistance\"),\n",
    "    (\"Something happened to my vehicle\", \"needs_clarification\"),\n",
    "    (\"LOL I just made up this story\", \"prank_call\"),\n",
    "    # Add more of your real examples here\n",
    "]\n",
    "\n",
    "# Convert to model inputs\n",
    "def prepare_examples(examples):\n",
    "    texts = [ex[0] for ex in examples]\n",
    "    labels = [categories.index(ex[1]) for ex in examples]\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    return encodings, torch.tensor(labels)\n",
    "\n",
    "train_encodings, train_labels = prepare_examples(training_examples)\n",
    "\n",
    "# Few-shot training\n",
    "optimizer = torch.optim.AdamW(classifier.parameters(), lr=5e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    train_encodings['input_ids'],\n",
    "    train_encodings['attention_mask'],\n",
    "    train_labels\n",
    ")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Train for a few epochs\n",
    "classifier.train()\n",
    "for epoch in range(3):\n",
    "    for batch in dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classifier(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Classification function using the lightweight model\n",
    "def classify_conversation(conversation: List[Dict]) -> str:\n",
    "    # Extract user messages\n",
    "    user_text = \" \".join([msg[\"content\"] for msg in conversation if msg[\"role\"] == \"user\"])\n",
    "    \n",
    "    # Tokenize and predict\n",
    "    inputs = tokenizer(user_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = classifier(**inputs)\n",
    "    \n",
    "    # Get predicted category\n",
    "    predicted_idx = torch.argmax(outputs).item()\n",
    "    return categories[predicted_idx]\n",
    "\n",
    "# Now use this in your data generation\n",
    "def generate_balanced_dataset_with_llm(target_per_category=25):\n",
    "    category_counts = {cat: 0 for cat in categories}\n",
    "    synthetic_data = []\n",
    "    \n",
    "    while min(category_counts.values()) < target_per_category:\n",
    "        new_conv = generate_synthetic_conversation()\n",
    "        category = classify_conversation(new_conv)\n",
    "        \n",
    "        if category_counts[category] < target_per_category:\n",
    "            synthetic_data.append(new_conv)\n",
    "            category_counts[category] += 1\n",
    "            print(f\"Generated {len(synthetic_data)}: {category}\")\n",
    "    \n",
    "    return synthetic_data\n",
    "\n",
    "# Generate the dataset\n",
    "balanced_data = generate_balanced_dataset_with_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T14:20:25.572559Z",
     "iopub.status.busy": "2025-05-24T14:20:25.572257Z",
     "iopub.status.idle": "2025-05-24T14:20:25.813022Z",
     "shell.execute_reply": "2025-05-24T14:20:25.812136Z",
     "shell.execute_reply.started": "2025-05-24T14:20:25.572538Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'faker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/2188397348.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfaker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFaker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'faker'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from faker import Faker\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize tools\n",
    "fake = Faker('el_GR')  # Greek locale for realistic names/locations\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 1. Generate 100+ Synthetic Conversations\n",
    "def generate_base_conversations():\n",
    "    base_conversations = []\n",
    "    \n",
    "    # Accident Care Examples (30)\n",
    "    for _ in range(30):\n",
    "        name = fake.name()\n",
    "        location = random.choice([\"Syntagma Square\", \"Thessaloniki Center\", \"Patras Harbor\"])\n",
    "        accident_type = random.choice([\"rear-end collision\", \"side impact\", \"head-on collision\"])\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": f\"I just had a {accident_type} accident near {location}! My name is {name}.\"},\n",
    "                {\"role\": \"assistant\", \"content\": f\"I'm sorry to hear about the accident Mr./Ms. {name.split()[-1]}. Are there any injuries?\"},\n",
    "                {\"role\": \"user\", \"content\": random.choice([\"No injuries but the car is damaged\", \"Yes, we need an ambulance\"])},\n",
    "                {\"role\": \"assistant\", \"content\": f\"We'll dispatch accident care to {location}. Is your car drivable?\"}\n",
    "            ],\n",
    "            \"category\": \"accident_care\"\n",
    "        })\n",
    "    \n",
    "    # Road Assistance Examples (30)\n",
    "    for _ in range(30):\n",
    "        name = fake.name()\n",
    "        car_type = random.choice([\"Toyota\", \"Honda\", \"BMW\", \"Mercedes\"])\n",
    "        issue = random.choice([\"won't start\", \"has a flat tire\", \"is overheating\"])\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": f\"My {car_type} {issue} on {fake.street_name()} Street. I'm {name}.\"},\n",
    "                {\"role\": \"assistant\", \"content\": f\"I understand you need assistance Mr./Ms. {name.split()[-1]}. What's your exact location?\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Near the {random.choice(['bank', 'supermarket', 'park'])} on {fake.street_name()} Street\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"We'll send roadside assistance within 45 minutes. Is the car in a safe location?\"}\n",
    "            ],\n",
    "            \"category\": \"road_assistance\"\n",
    "        })\n",
    "    \n",
    "    # Needs Clarification Examples (20)\n",
    "    for _ in range(20):\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": random.choice([\n",
    "                    \"My car has a problem\",\n",
    "                    \"Something happened to my vehicle\",\n",
    "                    \"I need help with my car\"\n",
    "                ])},\n",
    "                {\"role\": \"assistant\", \"content\": \"I'll help you. Could you please describe what happened with your vehicle?\"},\n",
    "                {\"role\": \"user\", \"content\": random.choice([\n",
    "                    \"It's not working right\",\n",
    "                    \"I'm not sure, it just stopped\",\n",
    "                    \"There was a noise\"\n",
    "                ])},\n",
    "                {\"role\": \"assistant\", \"content\": \"To better assist you, could you tell me your location and vehicle model?\"}\n",
    "            ],\n",
    "            \"category\": \"needs_clarification\"\n",
    "        })\n",
    "    \n",
    "    # Prank Call Examples (20)\n",
    "    for _ in range(20):\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": random.choice([\n",
    "                    \"LOL my car just flew away!\",\n",
    "                    \"I crashed into a unicorn\",\n",
    "                    \"Just kidding, testing your service\",\n",
    "                    \"My toaster is stuck in the car\"\n",
    "                ])},\n",
    "                {\"role\": \"assistant\", \"content\": \"This appears to be a non-serious inquiry. Please call back for genuine assistance.\"}\n",
    "            ],\n",
    "            \"category\": \"prank_call\"\n",
    "        })\n",
    "    \n",
    "    return base_conversations\n",
    "\n",
    "# Generate 100+ conversations\n",
    "all_conversations = generate_base_conversations()\n",
    "print(f\"Generated {len(all_conversations)} conversations\")\n",
    "\n",
    "# 2. Train and Save Classifier Model\n",
    "def train_and_save_classifier(conversations, save_path=\"/kaggle/working/insurance_classifier.pkl\"):\n",
    "    # Prepare training data\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for conv in conversations:\n",
    "        user_text = \" \".join([msg[\"content\"] for msg in conv[\"messages\"] if msg[\"role\"] == \"user\"])\n",
    "        texts.append(user_text)\n",
    "        labels.append(conv[\"category\"])\n",
    "    \n",
    "    # Initialize model\n",
    "    model_name = \"distilbert-base-multilingual-cased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=4,\n",
    "        id2label={0: \"accident_care\", 1: \"road_assistance\", 2: \"needs_clarification\", 3: \"prank_call\"},\n",
    "        label2id={\"accident_care\": 0, \"road_assistance\": 1, \"needs_clarification\": 2, \"prank_call\": 3}\n",
    "    ).to(device)\n",
    "    \n",
    "    # Tokenize data\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "    input_ids = encodings[\"input_ids\"].to(device)\n",
    "    attention_mask = encodings[\"attention_mask\"].to(device)\n",
    "    labels = torch.tensor([model.config.label2id[label] for label in labels]).to(device)\n",
    "    \n",
    "    # Train for a few epochs\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(3):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1} Loss: {loss.item()}\")\n",
    "    \n",
    "    # Save model\n",
    "    torch.save({\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"config\": model.config\n",
    "    }, save_path)\n",
    "    \n",
    "    print(f\"Model saved to {save_path}\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# Train and save model\n",
    "train_and_save_classifier(all_conversations)\n",
    "\n",
    "# 3. Save conversations to Kaggle\n",
    "with open(\"/kaggle/working/insurance_conversations.json\", \"w\") as f:\n",
    "    json.dump(all_conversations, f, indent=2)\n",
    "\n",
    "print(\"All files saved in Kaggle working directory:\")\n",
    "!ls /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T14:26:40.934841Z",
     "iopub.status.busy": "2025-05-24T14:26:40.934004Z",
     "iopub.status.idle": "2025-05-24T14:32:41.993277Z",
     "shell.execute_reply": "2025-05-24T14:32:41.992508Z",
     "shell.execute_reply.started": "2025-05-24T14:26:40.934814Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100 conversations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0.dev0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.3806347846984863\n",
      "Epoch 2 Loss: 1.2834265232086182\n",
      "Epoch 3 Loss: 1.1761353015899658\n",
      "Epoch 4 Loss: 1.1018908023834229\n",
      "Epoch 5 Loss: 1.0093439817428589\n",
      "Epoch 6 Loss: 0.9120502471923828\n",
      "Epoch 7 Loss: 0.8360320925712585\n",
      "Epoch 8 Loss: 0.7576269507408142\n",
      "Epoch 9 Loss: 0.6863073110580444\n",
      "Epoch 10 Loss: 0.6137562990188599\n",
      "Epoch 11 Loss: 0.5571959614753723\n",
      "Epoch 12 Loss: 0.4840092062950134\n",
      "Epoch 13 Loss: 0.4266722500324249\n",
      "Epoch 14 Loss: 0.3654012382030487\n",
      "Epoch 15 Loss: 0.3237764835357666\n",
      "Epoch 16 Loss: 0.2659647464752197\n",
      "Epoch 17 Loss: 0.23127581179141998\n",
      "Epoch 18 Loss: 0.19356413185596466\n",
      "Epoch 19 Loss: 0.16371271014213562\n",
      "Epoch 20 Loss: 0.14034779369831085\n",
      "Epoch 21 Loss: 0.11583144962787628\n",
      "Epoch 22 Loss: 0.10507556051015854\n",
      "Epoch 23 Loss: 0.0874115452170372\n",
      "Epoch 24 Loss: 0.07756716758012772\n",
      "Epoch 25 Loss: 0.0688028559088707\n",
      "Epoch 26 Loss: 0.059126969426870346\n",
      "Epoch 27 Loss: 0.05377170443534851\n",
      "Epoch 28 Loss: 0.04825491085648537\n",
      "Epoch 29 Loss: 0.042238205671310425\n",
      "Epoch 30 Loss: 0.04044985771179199\n",
      "Epoch 31 Loss: 0.036851320415735245\n",
      "Epoch 32 Loss: 0.03306036815047264\n",
      "Epoch 33 Loss: 0.030358953401446342\n",
      "Epoch 34 Loss: 0.027202650904655457\n",
      "Epoch 35 Loss: 0.02515537291765213\n",
      "Epoch 36 Loss: 0.02512502856552601\n",
      "Epoch 37 Loss: 0.02331451326608658\n",
      "Epoch 38 Loss: 0.021436544135212898\n",
      "Epoch 39 Loss: 0.020378444343805313\n",
      "Epoch 40 Loss: 0.01977490819990635\n",
      "Epoch 41 Loss: 0.017595630139112473\n",
      "Epoch 42 Loss: 0.016417108476161957\n",
      "Epoch 43 Loss: 0.015814809128642082\n",
      "Epoch 44 Loss: 0.01578170247375965\n",
      "Epoch 45 Loss: 0.015719279646873474\n",
      "Epoch 46 Loss: 0.014228316955268383\n",
      "Epoch 47 Loss: 0.013211829587817192\n",
      "Epoch 48 Loss: 0.013177207671105862\n",
      "Epoch 49 Loss: 0.012814895249903202\n",
      "Epoch 50 Loss: 0.011734205298125744\n",
      "Epoch 51 Loss: 0.011204664595425129\n",
      "Epoch 52 Loss: 0.011073722504079342\n",
      "Epoch 53 Loss: 0.01127629354596138\n",
      "Epoch 54 Loss: 0.010116871446371078\n",
      "Epoch 55 Loss: 0.010233765468001366\n",
      "Epoch 56 Loss: 0.00989525392651558\n",
      "Epoch 57 Loss: 0.009548729285597801\n",
      "Epoch 58 Loss: 0.009110572747886181\n",
      "Epoch 59 Loss: 0.0089533356949687\n",
      "Epoch 60 Loss: 0.00929923914372921\n",
      "Epoch 61 Loss: 0.008645354770123959\n",
      "Epoch 62 Loss: 0.008482003584504128\n",
      "Epoch 63 Loss: 0.007762836292386055\n",
      "Epoch 64 Loss: 0.008270378224551678\n",
      "Epoch 65 Loss: 0.007504971232265234\n",
      "Epoch 66 Loss: 0.007144158706068993\n",
      "Epoch 67 Loss: 0.007176922634243965\n",
      "Epoch 68 Loss: 0.007456932216882706\n",
      "Epoch 69 Loss: 0.007195892743766308\n",
      "Epoch 70 Loss: 0.007292717695236206\n",
      "Epoch 71 Loss: 0.0069861519150435925\n",
      "Epoch 72 Loss: 0.006636727601289749\n",
      "Epoch 73 Loss: 0.006715421564877033\n",
      "Epoch 74 Loss: 0.0062918895855546\n",
      "Epoch 75 Loss: 0.006164416205137968\n",
      "Epoch 76 Loss: 0.006501513533294201\n",
      "Epoch 77 Loss: 0.006157729774713516\n",
      "Epoch 78 Loss: 0.006099372636526823\n",
      "Epoch 79 Loss: 0.00596871180459857\n",
      "Epoch 80 Loss: 0.005772493313997984\n",
      "Epoch 81 Loss: 0.005626262631267309\n",
      "Epoch 82 Loss: 0.00573379173874855\n",
      "Epoch 83 Loss: 0.005681104026734829\n",
      "Epoch 84 Loss: 0.0052245669066905975\n",
      "Epoch 85 Loss: 0.005748639814555645\n",
      "Epoch 86 Loss: 0.005136106163263321\n",
      "Epoch 87 Loss: 0.005165714770555496\n",
      "Epoch 88 Loss: 0.005156862083822489\n",
      "Epoch 89 Loss: 0.005055457819253206\n",
      "Epoch 90 Loss: 0.004993993788957596\n",
      "Epoch 91 Loss: 0.004778392147272825\n",
      "Epoch 92 Loss: 0.004964861553162336\n",
      "Epoch 93 Loss: 0.00496254675090313\n",
      "Epoch 94 Loss: 0.004634565208107233\n",
      "Epoch 95 Loss: 0.004446851089596748\n",
      "Epoch 96 Loss: 0.004311281256377697\n",
      "Epoch 97 Loss: 0.0044115521013736725\n",
      "Epoch 98 Loss: 0.004372765775769949\n",
      "Epoch 99 Loss: 0.004426239524036646\n",
      "Epoch 100 Loss: 0.004393625073134899\n",
      "Model saved to /kaggle/working/insurance_classifier\n",
      "\n",
      "All files saved in Kaggle working directory:\n",
      "insurance_classifier  insurance_conversations.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# 1. Generate 100+ Synthetic Conversations without Faker\n",
    "def generate_greek_names(count=50):\n",
    "    first_names = [\"Dimitris\", \"Maria\", \"Yannis\", \"Eleni\", \"Nikos\", \n",
    "                  \"Sophia\", \"Andreas\", \"Katerina\", \"George\", \"Anna\"]\n",
    "    last_names = [\"Papadopoulos\", \"Ioannou\", \"Georgiou\", \"Karagiannis\", \n",
    "                 \"Nikolaou\", \"Antoniou\", \"Vasileiou\", \"Pappas\", \"Oikonomou\"]\n",
    "    return [f\"{random.choice(first_names)} {random.choice(last_names)}\" for _ in range(count)]\n",
    "\n",
    "def generate_locations():\n",
    "    return [\"Syntagma Square, Athens\", \"Thessaloniki City Center\", \"Patras Harbor\", \n",
    "           \"Heraklion Central\", \"Larissa Main Street\", \"Volos Waterfront\", \n",
    "           \"Corfu Old Town\", \"Rhodes Medieval City\", \"Chania Venetian Port\"]\n",
    "\n",
    "def generate_base_conversations():\n",
    "    greek_names = generate_greek_names()\n",
    "    locations = generate_locations()\n",
    "    base_conversations = []\n",
    "    \n",
    "    # Categories and their counts\n",
    "    categories = {\n",
    "        \"accident_care\": 30,\n",
    "        \"road_assistance\": 30,\n",
    "        \"needs_clarification\": 20,\n",
    "        \"prank_call\": 20\n",
    "    }\n",
    "    \n",
    "    # Accident Care Examples\n",
    "    for _ in range(categories[\"accident_care\"]):\n",
    "        name = random.choice(greek_names)\n",
    "        location = random.choice(locations)\n",
    "        accident_type = random.choice([\"rear-end collision\", \"side impact\", \"head-on collision\"])\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": f\"I just had a {accident_type} accident near {location}! My name is {name}.\"},\n",
    "                {\"role\": \"assistant\", \"content\": f\"I'm sorry to hear about the accident Mr./Ms. {name.split()[-1]}. Are there any injuries?\"}\n",
    "            ],\n",
    "            \"category\": \"accident_care\"\n",
    "        })\n",
    "    \n",
    "    # Road Assistance Examples\n",
    "    for _ in range(categories[\"road_assistance\"]):\n",
    "        name = random.choice(greek_names)\n",
    "        car_type = random.choice([\"Toyota\", \"Honda\", \"BMW\", \"Mercedes\"])\n",
    "        issue = random.choice([\"won't start\", \"has a flat tire\", \"is overheating\"])\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": f\"My {car_type} {issue} on {random.choice(locations)}. I'm {name}.\"},\n",
    "                {\"role\": \"assistant\", \"content\": f\"I understand you need assistance Mr./Ms. {name.split()[-1]}. What's your exact location?\"}\n",
    "            ],\n",
    "            \"category\": \"road_assistance\"\n",
    "        })\n",
    "    \n",
    "    # Needs Clarification Examples\n",
    "    for _ in range(categories[\"needs_clarification\"]):\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": random.choice([\n",
    "                    \"My car has a problem\",\n",
    "                    \"Something happened to my vehicle\",\n",
    "                    \"I need help with my car\"\n",
    "                ])},\n",
    "                {\"role\": \"assistant\", \"content\": \"I'll help you. Could you please describe what happened with your vehicle?\"}\n",
    "            ],\n",
    "            \"category\": \"needs_clarification\"\n",
    "        })\n",
    "    \n",
    "    # Prank Call Examples\n",
    "    for _ in range(categories[\"prank_call\"]):\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": random.choice([\n",
    "                    \"LOL my car just flew away!\",\n",
    "                    \"I crashed into a unicorn\",\n",
    "                    \"Just kidding, testing your service\"\n",
    "                ])},\n",
    "                {\"role\": \"assistant\", \"content\": \"This appears to be a non-serious inquiry. Please call back for genuine assistance.\"}\n",
    "            ],\n",
    "            \"category\": \"prank_call\"\n",
    "        })\n",
    "    \n",
    "    return base_conversations\n",
    "\n",
    "# Generate 100+ conversations\n",
    "all_conversations = generate_base_conversations()\n",
    "print(f\"Generated {len(all_conversations)} conversations\")\n",
    "\n",
    "# 2. Train and Save Classifier Model\n",
    "def train_and_save_classifier(conversations):\n",
    "    # First install required packages\n",
    "    !pip install transformers torch\n",
    "    \n",
    "    # Prepare training data\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for conv in conversations:\n",
    "        user_text = \" \".join([msg[\"content\"] for msg in conv[\"messages\"] if msg[\"role\"] == \"user\"])\n",
    "        texts.append(user_text)\n",
    "        labels.append(conv[\"category\"])\n",
    "    \n",
    "    # Initialize model\n",
    "    model_name = \"distilbert-base-uncased\"  # Smaller than multilingual version\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=4,\n",
    "        id2label={0: \"accident_care\", 1: \"road_assistance\", 2: \"needs_clarification\", 3: \"prank_call\"},\n",
    "        label2id={\"accident_care\": 0, \"road_assistance\": 1, \"needs_clarification\": 2, \"prank_call\": 3}\n",
    "    )\n",
    "    \n",
    "    # Tokenize data\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "    input_ids = encodings[\"input_ids\"]\n",
    "    attention_mask = encodings[\"attention_mask\"]\n",
    "    labels = torch.tensor([model.config.label2id[label] for label in labels])\n",
    "    \n",
    "    # Train for a few epochs\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1} Loss: {loss.item()}\")\n",
    "    \n",
    "    # Save model\n",
    "    save_path = \"/kaggle/working/insurance_classifier\"\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    \n",
    "    print(f\"Model saved to {save_path}\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# Train and save model\n",
    "model, tokenizer = train_and_save_classifier(all_conversations)\n",
    "\n",
    "# 3. Save conversations to Kaggle\n",
    "with open(\"/kaggle/working/insurance_conversations.json\", \"w\") as f:\n",
    "    json.dump(all_conversations, f, indent=2)\n",
    "\n",
    "print(\"\\nAll files saved in Kaggle working directory:\")\n",
    "!ls /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T14:40:17.033994Z",
     "iopub.status.busy": "2025-05-24T14:40:17.033155Z",
     "iopub.status.idle": "2025-05-24T14:40:17.088214Z",
     "shell.execute_reply": "2025-05-24T14:40:17.087404Z",
     "shell.execute_reply.started": "2025-05-24T14:40:17.033955Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Testing Results:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classify_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/2422417648.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nModel Testing Results:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_cases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{test}' => {prediction}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classify_message' is not defined"
     ]
    }
   ],
   "source": [
    "# Test examples\n",
    "test_cases = [\n",
    "    \"I crashed my car near Syntagma Square\",\n",
    "    \"My Toyota won't start\",\n",
    "    \"Something's wrong with my vehicle\",\n",
    "    \"LOL just kidding about my car\"\n",
    "]\n",
    "\n",
    "print(\"\\nModel Testing Results:\")\n",
    "for test in test_cases:\n",
    "    prediction = classify_message(test, model, tokenizer, label_map)\n",
    "    print(f\"'{test}' => {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T14:52:27.260051Z",
     "iopub.status.busy": "2025-05-24T14:52:27.259408Z",
     "iopub.status.idle": "2025-05-24T14:53:44.882560Z",
     "shell.execute_reply": "2025-05-24T14:53:44.881609Z",
     "shell.execute_reply.started": "2025-05-24T14:52:27.260029Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3926774263381958\n",
      "Epoch 2, Loss: 1.3170080184936523\n",
      "Epoch 3, Loss: 1.2257301807403564\n",
      "Epoch 4, Loss: 1.1367565393447876\n",
      "Epoch 5, Loss: 1.030173897743225\n",
      "Epoch 6, Loss: 0.9215638637542725\n",
      "Epoch 7, Loss: 0.8287941813468933\n",
      "Epoch 8, Loss: 0.7390813231468201\n",
      "Epoch 9, Loss: 0.6663830280303955\n",
      "Epoch 10, Loss: 0.5982199311256409\n",
      "Epoch 11, Loss: 0.5208102464675903\n",
      "Epoch 12, Loss: 0.4686911404132843\n",
      "Epoch 13, Loss: 0.40472543239593506\n",
      "Epoch 14, Loss: 0.3505100905895233\n",
      "Epoch 15, Loss: 0.30248579382896423\n",
      "Epoch 16, Loss: 0.25744807720184326\n",
      "Epoch 17, Loss: 0.22002579271793365\n",
      "Epoch 18, Loss: 0.18347731232643127\n",
      "Epoch 19, Loss: 0.1562412977218628\n",
      "Epoch 20, Loss: 0.13636337220668793\n",
      "Model and tokenizer zipped to /kaggle/working/insurance_classifier.zip\n",
      "\n",
      "Test Predictions:\n",
      "> \"My car broke down on the highway\" → needs_clarification\n",
      "> \"I hit a pole in Thessaloniki\" → prank_call\n",
      "> \"Help me, something happened to my engine\" → prank_call\n",
      "> \"I just flew over Mount Olympus in my Ferrari lol\" → prank_call\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import zipfile\n",
    "import os\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# 1. Generate Synthetic Conversations\n",
    "def generate_greek_names(count=50):\n",
    "    first_names = [\"Dimitris\", \"Maria\", \"Yannis\", \"Eleni\", \"Nikos\", \"Sophia\", \"Andreas\", \"Katerina\", \"George\", \"Anna\"]\n",
    "    last_names = [\"Papadopoulos\", \"Ioannou\", \"Georgiou\", \"Karagiannis\", \"Nikolaou\", \"Antoniou\", \"Vasileiou\", \"Pappas\", \"Oikonomou\"]\n",
    "    return [f\"{random.choice(first_names)} {random.choice(last_names)}\" for _ in range(count)]\n",
    "\n",
    "def generate_locations():\n",
    "    return [\"Syntagma Square, Athens\", \"Thessaloniki City Center\", \"Patras Harbor\", \n",
    "            \"Heraklion Central\", \"Larissa Main Street\", \"Volos Waterfront\", \n",
    "            \"Corfu Old Town\", \"Rhodes Medieval City\", \"Chania Venetian Port\"]\n",
    "\n",
    "def generate_base_conversations():\n",
    "    greek_names = generate_greek_names()\n",
    "    locations = generate_locations()\n",
    "    base_conversations = []\n",
    "\n",
    "    categories = {\n",
    "        \"accident_care\": 30,\n",
    "        \"road_assistance\": 30,\n",
    "        \"needs_clarification\": 20,\n",
    "        \"prank_call\": 20\n",
    "    }\n",
    "\n",
    "    for _ in range(categories[\"accident_care\"]):\n",
    "        name = random.choice(greek_names)\n",
    "        location = random.choice(locations)\n",
    "        accident_type = random.choice([\"rear-end collision\", \"side impact\", \"head-on collision\"])\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": f\"I just had a {accident_type} accident near {location}! My name is {name}.\"},\n",
    "                {\"role\": \"assistant\", \"content\": f\"I'm sorry to hear about the accident Mr./Ms. {name.split()[-1]}. Are there any injuries?\"}\n",
    "            ],\n",
    "            \"category\": \"accident_care\"\n",
    "        })\n",
    "\n",
    "    for _ in range(categories[\"road_assistance\"]):\n",
    "        name = random.choice(greek_names)\n",
    "        car_type = random.choice([\"Toyota\", \"Honda\", \"BMW\", \"Mercedes\"])\n",
    "        issue = random.choice([\"won't start\", \"has a flat tire\", \"is overheating\"])\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": f\"My {car_type} {issue} on {random.choice(locations)}. I'm {name}.\"},\n",
    "                {\"role\": \"assistant\", \"content\": f\"I understand you need assistance Mr./Ms. {name.split()[-1]}. What's your exact location?\"}\n",
    "            ],\n",
    "            \"category\": \"road_assistance\"\n",
    "        })\n",
    "\n",
    "    for _ in range(categories[\"needs_clarification\"]):\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": random.choice([\n",
    "                    \"My car has a problem\",\n",
    "                    \"Something happened to my vehicle\",\n",
    "                    \"I need help with my car\"\n",
    "                ])},\n",
    "                {\"role\": \"assistant\", \"content\": \"I'll help you. Could you please describe what happened with your vehicle?\"}\n",
    "            ],\n",
    "            \"category\": \"needs_clarification\"\n",
    "        })\n",
    "\n",
    "    for _ in range(categories[\"prank_call\"]):\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": random.choice([\n",
    "                    \"LOL my car just flew away!\",\n",
    "                    \"I crashed into a unicorn\",\n",
    "                    \"Just kidding, testing your service\"\n",
    "                ])},\n",
    "                {\"role\": \"assistant\", \"content\": \"This appears to be a non-serious inquiry. Please call back for genuine assistance.\"}\n",
    "            ],\n",
    "            \"category\": \"prank_call\"\n",
    "        })\n",
    "\n",
    "    return base_conversations\n",
    "\n",
    "all_conversations = generate_base_conversations()\n",
    "\n",
    "# 2. Train and Save the Model\n",
    "def train_and_save_classifier(conversations, save_path=\"/kaggle/working/insurance_classifier\"):\n",
    "    texts = [\" \".join([msg[\"content\"] for msg in conv[\"messages\"] if msg[\"role\"] == \"user\"]) for conv in conversations]\n",
    "    labels = [conv[\"category\"] for conv in conversations]\n",
    "\n",
    "    label2id = {\"accident_care\": 0, \"road_assistance\": 1, \"needs_clarification\": 2, \"prank_call\": 3}\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\",\n",
    "        num_labels=4,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "    input_ids = encodings[\"input_ids\"]\n",
    "    attention_mask = encodings[\"attention_mask\"]\n",
    "    targets = torch.tensor([label2id[label] for label in labels])\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(20):  # use 5 for speed, increase if needed\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=targets)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "    # Save model and tokenizer\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "\n",
    "    # Zip model\n",
    "    zip_path = save_path + \".zip\"\n",
    "    with zipfile.ZipFile(zip_path, \"w\") as zipf:\n",
    "        for folder, _, files in os.walk(save_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(folder, file)\n",
    "                zipf.write(file_path, arcname=os.path.relpath(file_path, save_path))\n",
    "\n",
    "    print(f\"Model and tokenizer zipped to {zip_path}\")\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = train_and_save_classifier(all_conversations)\n",
    "\n",
    "# 3. Save Conversations\n",
    "with open(\"/kaggle/working/insurance_conversations.json\", \"w\") as f:\n",
    "    json.dump(all_conversations, f, indent=2)\n",
    "\n",
    "# 4. Test the Model\n",
    "def predict_category(text, model, tokenizer):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted = torch.argmax(logits, dim=1).item()\n",
    "    return model.config.id2label[predicted]\n",
    "\n",
    "test_inputs = [\n",
    "    \"My car broke down on the highway\",\n",
    "    \"I hit a pole in Thessaloniki\",\n",
    "    \"Help me, something happened to my engine\",\n",
    "    \"I just flew over Mount Olympus in my Ferrari lol\"\n",
    "]\n",
    "\n",
    "print(\"\\nTest Predictions:\")\n",
    "for input_text in test_inputs:\n",
    "    category = predict_category(input_text, model, tokenizer)\n",
    "    print(f\"> \\\"{input_text}\\\" → {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T14:50:50.580724Z",
     "iopub.status.busy": "2025-05-24T14:50:50.580016Z",
     "iopub.status.idle": "2025-05-24T14:50:50.592858Z",
     "shell.execute_reply": "2025-05-24T14:50:50.591893Z",
     "shell.execute_reply.started": "2025-05-24T14:50:50.580693Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '(' (1562594428.py, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_35/1562594428.py\"\u001b[0;36m, line \u001b[0;32m43\u001b[0m\n\u001b[0;31m    texts = [\" \".join(m[\"content\"] for m in conv[\"messages\"] if m[\"role\"] == \"user\"] for conv in conversations]\u001b[0m\n\u001b[0m                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '('\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# 1. Generate Synthetic Conversations (same as before)\n",
    "def generate_greek_names(count=50):\n",
    "    first_names = [\"Dimitris\", \"Maria\", \"Yannis\", \"Eleni\", \"Nikos\", \n",
    "                  \"Sophia\", \"Andreas\", \"Katerina\", \"George\", \"Anna\"]\n",
    "    last_names = [\"Papadopoulos\", \"Ioannou\", \"Georgiou\", \"Karagiannis\", \n",
    "                 \"Nikolaou\", \"Antoniou\", \"Vasileiou\", \"Pappas\", \"Oikonomou\"]\n",
    "    return [f\"{random.choice(first_names)} {random.choice(last_names)}\" for _ in range(count)]\n",
    "\n",
    "def generate_locations():\n",
    "    return [\"Syntagma Square, Athens\", \"Thessaloniki City Center\", \"Patras Harbor\", \n",
    "           \"Heraklion Central\", \"Larissa Main Street\", \"Volos Waterfront\", \n",
    "           \"Corfu Old Town\", \"Rhodes Medieval City\", \"Chania Venetian Port\"]\n",
    "\n",
    "def generate_base_conversations():\n",
    "    greek_names = generate_greek_names()\n",
    "    locations = generate_locations()\n",
    "    base_conversations = []\n",
    "    \n",
    "    categories = {\n",
    "        \"accident_care\": 30,\n",
    "        \"road_assistance\": 30,\n",
    "        \"needs_clarification\": 20,\n",
    "        \"prank_call\": 20\n",
    "    }\n",
    "    \n",
    "    # [Previous conversation generation code remains exactly the same]\n",
    "    # ... (keep all your existing conversation generation code)\n",
    "\n",
    "# Generate conversations\n",
    "all_conversations = generate_base_conversations()\n",
    "\n",
    "# 2. Enhanced Model Training with Evaluation\n",
    "def train_and_save_classifier(conversations):\n",
    "    # Prepare data\n",
    "    texts = [\" \".join(m[\"content\"] for m in conv[\"messages\"] if m[\"role\"] == \"user\"] for conv in conversations]\n",
    "    labels = [conv[\"category\"] for conv in conversations]\n",
    "    \n",
    "    # Initialize model\n",
    "    model_name = \"distilbert-base-uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=4,\n",
    "        id2label={0: \"accident_care\", 1: \"road_assistance\", 2: \"needs_clarification\", 3: \"prank_call\"},\n",
    "        label2id={\"accident_care\": 0, \"road_assistance\": 1, \"needs_clarification\": 2, \"prank_call\": 3}\n",
    "    )\n",
    "    \n",
    "    # Tokenize\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "    input_ids = encodings[\"input_ids\"]\n",
    "    attention_mask = encodings[\"attention_mask\"]\n",
    "    labels = torch.tensor([model.config.label2id[label] for label in labels])\n",
    "    \n",
    "    # Train with progress tracking\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Reduced epochs for Kaggle\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Save in multiple formats\n",
    "    save_dir = \"/kaggle/working/insurance_model\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Format 1: Native Hugging Face format\n",
    "    model.save_pretrained(save_dir)\n",
    "    tokenizer.save_pretrained(save_dir)\n",
    "    \n",
    "    # Format 2: Pickle file\n",
    "    with open(f\"{save_dir}/model.pkl\", \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"tokenizer\": tokenizer,\n",
    "            \"config\": model.config\n",
    "        }, f)\n",
    "    \n",
    "    # Format 3: Compressed ZIP\n",
    "    with ZipFile(f\"{save_dir}/model.zip\", 'w') as zipf:\n",
    "        for root, _, files in os.walk(save_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.pkl') or file.endswith('.json'):\n",
    "                    zipf.write(os.path.join(root, file), file)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "# Train and save\n",
    "model, tokenizer = train_and_save_classifier(all_conversations)\n",
    "\n",
    "# 3. Save conversations\n",
    "with open(\"/kaggle/working/insurance_conversations.json\", \"w\") as f:\n",
    "    json.dump(all_conversations, f, indent=2)\n",
    "\n",
    "# 4. Model Testing\n",
    "test_questions = [\n",
    "    \"I crashed my car near the airport\",\n",
    "    \"My Honda won't start in Thessaloniki\",\n",
    "    \"Something's wrong with my vehicle\",\n",
    "    \"LOL my car turned into a banana\",\n",
    "    \"There was a collision on the highway\",\n",
    "    \"Just testing your system\",\n",
    "    \"My BMW is overheating\",\n",
    "    \"I need help with my Fiat\"\n",
    "]\n",
    "\n",
    "def test_model(model, tokenizer, questions):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MODEL TESTING RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    model.eval()\n",
    "    for question in questions:\n",
    "        inputs = tokenizer(question, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        pred = model.config.id2label[outputs.logits.argmax().item()]\n",
    "        print(f\"Question: {question[:60]}...\")\n",
    "        print(f\"Prediction: {pred}\\n\")\n",
    "\n",
    "test_model(model, tokenizer, test_questions)\n",
    "\n",
    "# 5. Prepare Downloadable Files\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DOWNLOADABLE FILES\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. insurance_model/ - Full model directory\")\n",
    "print(\"2. insurance_model/model.pkl - Pickle format\")\n",
    "print(\"3. insurance_model/model.zip - Compressed bundle\")\n",
    "print(\"4. insurance_conversations.json - All training data\")\n",
    "\n",
    "# Create download instructions\n",
    "with open(\"/kaggle/working/README.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"HOW TO DOWNLOAD:\n",
    "1. Click the folder icon on the left\n",
    "2. Navigate to /kaggle/working/\n",
    "3. Check the files you want\n",
    "4. Click the 'Download' button\n",
    "\n",
    "Files available:\n",
    "- insurance_model/ (full model)\n",
    "- insurance_model/model.pkl (pickle version)\n",
    "- insurance_model/model.zip (compressed)\n",
    "- insurance_conversations.json (training data)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nTo download: Check /kaggle/working/ in the file browser and click Download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T15:15:30.915190Z",
     "iopub.status.busy": "2025-05-24T15:15:30.914888Z",
     "iopub.status.idle": "2025-05-24T15:18:36.307838Z",
     "shell.execute_reply": "2025-05-24T15:18:36.307186Z",
     "shell.execute_reply.started": "2025-05-24T15:15:30.915169Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100 conversations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.3794\n",
      "Epoch 2 Loss: 1.2819\n",
      "Epoch 3 Loss: 1.1707\n",
      "Epoch 4 Loss: 1.0769\n",
      "Epoch 5 Loss: 0.9768\n",
      "Epoch 6 Loss: 0.8736\n",
      "Epoch 7 Loss: 0.7859\n",
      "Epoch 8 Loss: 0.6806\n",
      "Epoch 9 Loss: 0.6034\n",
      "Epoch 10 Loss: 0.5310\n",
      "Epoch 11 Loss: 0.4556\n",
      "Epoch 12 Loss: 0.3908\n",
      "Epoch 13 Loss: 0.3280\n",
      "Epoch 14 Loss: 0.2724\n",
      "Epoch 15 Loss: 0.2301\n",
      "Epoch 16 Loss: 0.2100\n",
      "Epoch 17 Loss: 0.1708\n",
      "Epoch 18 Loss: 0.1502\n",
      "Epoch 19 Loss: 0.1293\n",
      "Epoch 20 Loss: 0.1113\n",
      "Epoch 21 Loss: 0.0983\n",
      "Epoch 22 Loss: 0.0850\n",
      "Epoch 23 Loss: 0.0774\n",
      "Epoch 24 Loss: 0.0674\n",
      "Epoch 25 Loss: 0.0606\n",
      "Epoch 26 Loss: 0.0551\n",
      "Epoch 27 Loss: 0.0496\n",
      "Epoch 28 Loss: 0.0457\n",
      "Epoch 29 Loss: 0.0402\n",
      "Epoch 30 Loss: 0.0391\n",
      "Epoch 31 Loss: 0.0345\n",
      "Epoch 32 Loss: 0.0319\n",
      "Epoch 33 Loss: 0.0303\n",
      "Epoch 34 Loss: 0.0268\n",
      "Epoch 35 Loss: 0.0257\n",
      "Epoch 36 Loss: 0.0246\n",
      "Epoch 37 Loss: 0.0226\n",
      "Epoch 38 Loss: 0.0216\n",
      "Epoch 39 Loss: 0.0198\n",
      "Epoch 40 Loss: 0.0196\n",
      "Epoch 41 Loss: 0.0184\n",
      "Epoch 42 Loss: 0.0184\n",
      "Epoch 43 Loss: 0.0163\n",
      "Epoch 44 Loss: 0.0157\n",
      "Epoch 45 Loss: 0.0142\n",
      "Epoch 46 Loss: 0.0145\n",
      "Epoch 47 Loss: 0.0139\n",
      "Epoch 48 Loss: 0.0139\n",
      "Epoch 49 Loss: 0.0125\n",
      "Epoch 50 Loss: 0.0123\n",
      "\n",
      "==================================================\n",
      "MODEL TESTING RESULTS\n",
      "==================================================\n",
      "Question: I crashed my car near the airport...\n",
      "Prediction: prank_call\n",
      "\n",
      "Question: My Honda won't start in Thessaloniki...\n",
      "Prediction: needs_clarification\n",
      "\n",
      "Question: Something's wrong with my vehicle...\n",
      "Prediction: needs_clarification\n",
      "\n",
      "Question: LOL my car turned into a banana...\n",
      "Prediction: prank_call\n",
      "\n",
      "Question: There was a collision on the highway...\n",
      "Prediction: needs_clarification\n",
      "\n",
      "Question: Just testing your system...\n",
      "Prediction: prank_call\n",
      "\n",
      "Question: My BMW is overheating...\n",
      "Prediction: needs_clarification\n",
      "\n",
      "Question: I need help with my Fiat...\n",
      "Prediction: needs_clarification\n",
      "\n",
      "\n",
      "==================================================\n",
      "DOWNLOADABLE FILES\n",
      "==================================================\n",
      "1. insurance_model/ - Full model directory\n",
      "2. insurance_model/model.pkl - Pickle format\n",
      "3. insurance_model/model.zip - Compressed bundle\n",
      "4. insurance_conversations.json - All training data\n",
      "\n",
      "To download: Check /kaggle/working/ in the file browser and click Download\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# 1. Generate Synthetic Conversations\n",
    "def generate_greek_names(count=50):\n",
    "    first_names = [\"Dimitris\", \"Maria\", \"Yannis\", \"Eleni\", \"Nikos\", \n",
    "                  \"Sophia\", \"Andreas\", \"Katerina\", \"George\", \"Anna\"]\n",
    "    last_names = [\"Papadopoulos\", \"Ioannou\", \"Georgiou\", \"Karagiannis\", \n",
    "                 \"Nikolaou\", \"Antoniou\", \"Vasileiou\", \"Pappas\", \"Oikonomou\"]\n",
    "    return [f\"{random.choice(first_names)} {random.choice(last_names)}\" for _ in range(count)]\n",
    "\n",
    "def generate_locations():\n",
    "    return [\"Syntagma Square, Athens\", \"Thessaloniki City Center\", \"Patras Harbor\", \n",
    "           \"Heraklion Central\", \"Larissa Main Street\", \"Volos Waterfront\", \n",
    "           \"Corfu Old Town\", \"Rhodes Medieval City\", \"Chania Venetian Port\"]\n",
    "\n",
    "def generate_base_conversations():\n",
    "    greek_names = generate_greek_names()\n",
    "    locations = generate_locations()\n",
    "    base_conversations = []\n",
    "    \n",
    "    categories = {\n",
    "        \"accident_care\": 30,\n",
    "        \"road_assistance\": 30,\n",
    "        \"needs_clarification\": 20,\n",
    "        \"prank_call\": 20\n",
    "    }\n",
    "    \n",
    "    # Accident Care Examples\n",
    "    for _ in range(categories[\"accident_care\"]):\n",
    "        name = random.choice(greek_names)\n",
    "        location = random.choice(locations)\n",
    "        accident_type = random.choice([\"rear-end collision\", \"side impact\", \"head-on collision\"])\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": f\"I just had a {accident_type} accident near {location}! My name is {name}.\"},\n",
    "                {\"role\": \"assistant\", \"content\": f\"I'm sorry to hear about the accident Mr./Ms. {name.split()[-1]}. Are there any injuries?\"}\n",
    "            ],\n",
    "            \"category\": \"accident_care\"\n",
    "        })\n",
    "    \n",
    "    # Road Assistance Examples\n",
    "    for _ in range(categories[\"road_assistance\"]):\n",
    "        name = random.choice(greek_names)\n",
    "        car_type = random.choice([\"Toyota\", \"Honda\", \"BMW\", \"Mercedes\"])\n",
    "        issue = random.choice([\"won't start\", \"has a flat tire\", \"is overheating\"])\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": f\"My {car_type} {issue} on {random.choice(locations)}. I'm {name}.\"},\n",
    "                {\"role\": \"assistant\", \"content\": f\"I understand you need assistance Mr./Ms. {name.split()[-1]}. What's your exact location?\"}\n",
    "            ],\n",
    "            \"category\": \"road_assistance\"\n",
    "        })\n",
    "    \n",
    "    # Needs Clarification Examples\n",
    "    for _ in range(categories[\"needs_clarification\"]):\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "                {\"role\": \"user\", \"content\": random.choice([\n",
    "                    \"My car has a problem\",\n",
    "                    \"Something happened to my vehicle\",\n",
    "                    \"I need help with my car\"\n",
    "                ])},\n",
    "                {\"role\": \"assistant\", \"content\": \"I'll help you. Could you please describe what happened with your vehicle?\"}\n",
    "            ],\n",
    "            \"category\": \"needs_clarification\"\n",
    "        })\n",
    "    \n",
    "    # Prank Call Examples\n",
    "    for _ in range(categories[\"prank_call\"]):\n",
    "        base_conversations.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"\"\"You are an AI assistant for the insurance company named Greek Insurance Company.\n",
    "                You will be contacted by different types of people when they have a problem with their car.\n",
    "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
    "                The four character categories are:\n",
    "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
    "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
    "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
    "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
    "                 \"\"\"},\n",
    "                {\"role\": \"user\", \"content\": random.choice([\n",
    "                    \"LOL my car just flew away!\",\n",
    "                    \"I crashed into a unicorn\",\n",
    "                    \"Just kidding, testing your service\"\n",
    "                ])},\n",
    "                {\"role\": \"assistant\", \"content\": \"This appears to be a non-serious inquiry. Please call back for genuine assistance.\"}\n",
    "            ],\n",
    "            \"category\": \"prank_call\"\n",
    "        })\n",
    "    \n",
    "    return base_conversations\n",
    "\n",
    "# Generate conversations\n",
    "all_conversations = generate_base_conversations()\n",
    "print(f\"Generated {len(all_conversations)} conversations\")\n",
    "\n",
    "# 2. Train and Save Classifier Model\n",
    "def train_and_save_classifier(conversations):\n",
    "    # Prepare training data - FIXED THE SYNTAX ERROR HERE\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for conv in conversations:\n",
    "        user_messages = [m[\"content\"] for m in conv[\"messages\"] if m[\"role\"] == \"user\"]\n",
    "        texts.append(\" \".join(user_messages))\n",
    "        labels.append(conv[\"category\"])\n",
    "    \n",
    "    # Initialize model\n",
    "    model_name = \"distilbert-base-uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=4,\n",
    "        id2label={0: \"accident_care\", 1: \"road_assistance\", 2: \"needs_clarification\", 3: \"prank_call\"},\n",
    "        label2id={\"accident_care\": 0, \"road_assistance\": 1, \"needs_clarification\": 2, \"prank_call\": 3}\n",
    "    )\n",
    "    \n",
    "    # Tokenize data\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "    input_ids = encodings[\"input_ids\"]\n",
    "    attention_mask = encodings[\"attention_mask\"]\n",
    "    labels = torch.tensor([model.config.label2id[label] for label in labels])\n",
    "    \n",
    "    # Train with progress tracking\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    model.train()\n",
    "    for epoch in range(50):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Save in multiple formats\n",
    "    save_dir = \"/kaggle/working/insurance_model\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Format 1: Native Hugging Face format\n",
    "    model.save_pretrained(save_dir)\n",
    "    tokenizer.save_pretrained(save_dir)\n",
    "    \n",
    "    # Format 2: Pickle file\n",
    "    with open(f\"{save_dir}/model.pkl\", \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"tokenizer\": tokenizer,\n",
    "            \"config\": model.config\n",
    "        }, f)\n",
    "    \n",
    "    # Format 3: Compressed ZIP\n",
    "    with ZipFile(f\"{save_dir}/model.zip\", 'w') as zipf:\n",
    "        for root, _, files in os.walk(save_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.pkl') or file.endswith('.json'):\n",
    "                    zipf.write(os.path.join(root, file), file)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "# Train and save\n",
    "model, tokenizer = train_and_save_classifier(all_conversations)\n",
    "\n",
    "# 3. Save conversations\n",
    "with open(\"/kaggle/working/insurance_conversations.json\", \"w\") as f:\n",
    "    json.dump(all_conversations, f, indent=2)\n",
    "\n",
    "# 4. Model Testing\n",
    "test_questions = [\n",
    "    \"I crashed my car near the airport\",\n",
    "    \"My Honda won't start in Thessaloniki\",\n",
    "    \"Something's wrong with my vehicle\",\n",
    "    \"LOL my car turned into a banana\",\n",
    "    \"There was a collision on the highway\",\n",
    "    \"Just testing your system\",\n",
    "    \"My BMW is overheating\",\n",
    "    \"I need help with my Fiat\"\n",
    "]\n",
    "\n",
    "def test_model(model, tokenizer, questions):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MODEL TESTING RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    model.eval()\n",
    "    for question in questions:\n",
    "        inputs = tokenizer(question, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        pred = model.config.id2label[outputs.logits.argmax().item()]\n",
    "        print(f\"Question: {question[:60]}...\")\n",
    "        print(f\"Prediction: {pred}\\n\")\n",
    "\n",
    "test_model(model, tokenizer, test_questions)\n",
    "\n",
    "# 5. Prepare Downloadable Files\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DOWNLOADABLE FILES\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. insurance_model/ - Full model directory\")\n",
    "print(\"2. insurance_model/model.pkl - Pickle format\")\n",
    "print(\"3. insurance_model/model.zip - Compressed bundle\")\n",
    "print(\"4. insurance_conversations.json - All training data\")\n",
    "\n",
    "# Create download instructions\n",
    "with open(\"/kaggle/working/README.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"HOW TO DOWNLOAD:\n",
    "1. Click the folder icon on the left\n",
    "2. Navigate to /kaggle/working/\n",
    "3. Check the files you want\n",
    "4. Click the 'Download' button\n",
    "\n",
    "Files available:\n",
    "- insurance_model/ (full model)\n",
    "- insurance_model/model.pkl (pickle version)\n",
    "- insurance_model/model.zip (compressed)\n",
    "- insurance_conversations.json (training data)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nTo download: Check /kaggle/working/ in the file browser and click Download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T15:35:20.516764Z",
     "iopub.status.busy": "2025-05-24T15:35:20.516237Z",
     "iopub.status.idle": "2025-05-24T15:35:20.536031Z",
     "shell.execute_reply": "2025-05-24T15:35:20.535314Z",
     "shell.execute_reply.started": "2025-05-24T15:35:20.516741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_examples = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Hello! How can I assist you?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hello. I just had a car accident.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I'm sorry to hear that! How long ago did it happen?\"},\n",
    "            {\"role\": \"user\", \"content\": \"About fifteen minutes ago.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I'd like to know if there are any injuries.\"},\n",
    "            {\"role\": \"user\", \"content\": \"No, fortunately, we are all fine. There’s only material damage.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I'm glad to hear everyone is okay! I’ll need to collect some of your details. Let's start with your vehicle’s license plate number.\"},\n",
    "            {\"role\": \"user\", \"content\": \"The plate number is MNR-9012.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Additionally, I’d like to know under whose name the insurance policy is registered.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Under the name Pinelopi Papachristou.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Very well! Am I speaking with her directly?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Yes, it’s me in person.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Would you like to describe to us exactly how the accident happened?\"},\n",
    "            {\"role\": \"user\", \"content\": \"I was stopped on Vouliagmenis Avenue, at the traffic light at the intersection with Zeppou Street, and a vehicle hit me from behind.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Very helpful. I’d also like you to tell me exactly where the damage is located on your vehicle.\"},\n",
    "            {\"role\": \"user\", \"content\": \"On the rear light and the rear bumper.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Understood. Do you need me to call roadside assistance?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Yes, I would like that.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Of course, I’m calling roadside assistance to your location right away. Do you also have the details of the driver of the other vehicle involved in the collision (name, surname, phone number, insurance company)?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Yes. His name is Panagiotis Antoniou, his phone number is 6986345752 and his insurance company is Anytime.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Do you know if Anytime has already been notified and whether the driver accepts responsibility for the incident?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Yes, both the insurance company has been notified and Mr. Antoniou accepts responsibility for the accident.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Thank you for the information. The accident report is now complete, and roadside assistance will arrive at the scene shortly. Below you’ll find a discount coupon to use at nearby supermarkets while you wait for assistance.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Thank you very much for your help!\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Hello! How can I assist you?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hi, my car won’t start and I’m stuck in the middle of the road.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I’m sorry to hear that. How long have you been stopped there?\"},\n",
    "            {\"role\": \"user\", \"content\": \"About 10 minutes.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I’ll need your vehicle’s license plate number and your full name, please.\"},\n",
    "            {\"role\": \"user\", \"content\": \"The plate number is IMO1806 and my name is Ioannis Papadopoulos.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Understood. Could you also give me your exact location?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Yes, 19-21 Damareos Street in Pagrati, between Kononos and Artotinis.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I’ll call roadside assistance right away to come to your location. Is there anyone in the vehicle who needs special assistance or is there any other emergency?\"},\n",
    "            {\"role\": \"user\", \"content\": \"No, fortunately everyone is fine.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Glad to hear that. I’ve contacted roadside assistance and they’ll be at your location within 10 minutes. Below you’ll find a coupon you can use at nearby shops while you wait. Thank you very much for contacting us.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Thank you very much as well.\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Hello! How can I assist you?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hello, I just had a minor collision in the supermarket parking lot.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I’m sorry to hear that. Are there any injuries?\"},\n",
    "            {\"role\": \"user\", \"content\": \"No, fortunately we’re all fine. Just minor material damage.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Alright, that’s the most important thing. I’d like you to give me your vehicle’s license plate number and your full name.\"},\n",
    "            {\"role\": \"user\", \"content\": \"The plate number is YRZ3456 and my name is Eleni Konstantinou.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Understood. Could you give me your exact location and, if possible, the plate number of the other vehicle?\"},\n",
    "            {\"role\": \"user\", \"content\": \"I’m at the AB Vasilopoulos parking lot on 123 Thivon Street, in Peristeri. The other vehicle’s plate number is ZKM7890.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Thank you. I’ll contact the nearest roadside assistance service to come and collect your vehicle. It should be at your location in about 15–20 minutes. Below you’ll find a coupon you can use at nearby shops while you wait. Thank you very much for contacting us.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Thank you as well.\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Hello! How can I assist you?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hello, my car was damaged by the recent hailstorm.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I'm sorry to hear that. Are there any injuries?\"},\n",
    "            {\"role\": \"user\", \"content\": \"No, fortunately I was inside the house. Only the car has dents on the hood and roof.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Understood. I’d like you to give me your vehicle’s license plate number and your full name.\"},\n",
    "            {\"role\": \"user\", \"content\": \"The license plate number is POM4567 and my name is Sofia Dimitriou.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Got it. Could you tell me the exact location where the incident occurred and give me a brief description of the damage?\"},\n",
    "            {\"role\": \"user\", \"content\": \"It was parked at 30 Evangelistrias Street, in Kifisia. There are several dents from the hail, mainly on the hood, roof, and trunk.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I understand. I will immediately contact roadside assistance to have your vehicle taken to the nearest repair shop if you wish.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Yes, please.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Perfect. Roadside assistance will arrive shortly at your location. Below, you’ll find a coupon you can use at nearby shops while you wait. Thank you very much for contacting us.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Thank you.\"}\n",
    "        ]\n",
    "    },\n",
    "        {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Good evening! How can I help you today?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Good evening, I had a minor car accident with another vehicle and I need assistance.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I'm sorry to hear that. Are you and your passengers okay?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Yes, fortunately there are no injuries.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Could you please tell me exactly where the accident happened?\"},\n",
    "            {\"role\": \"user\", \"content\": \"On Athinas Street, near the intersection with Solonos Street.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Thank you. I’ll also need your vehicle's license plate number and your name.\"},\n",
    "            {\"role\": \"user\", \"content\": \"The license plate number is ABG1234 and my name is Maria Konstantinou.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Understood. I’ve recorded your details. I will forward your request for damage assessment and we will call you shortly with the next steps. Do you need roadside assistance?\"},\n",
    "            {\"role\": \"user\", \"content\": \"No, the vehicle can be driven to the nearest repair shop.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Excellent. Please make sure to keep the other party's details for the insurance process. Thank you for contacting us.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Thank you very much as well.\"}\n",
    "        ]\n",
    "    },\n",
    "        {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Good evening! How can I help you today?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Good evening, my car has broken down due to an engine failure and it won't start.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"How long have you been stopped there?\"},\n",
    "            {\"role\": \"user\", \"content\": \"About 15 minutes.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Could you please give me your license plate number and full name?\"},\n",
    "            {\"role\": \"user\", \"content\": \"The plate number is ZXY5678 and my name is Dimitris Papadopoulos.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Could you also tell me your exact location?\"},\n",
    "            {\"role\": \"user\", \"content\": \"I'm on Mesogeion Avenue 45, near the metro station.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I will immediately call roadside assistance to come to your location. Is there anything that needs urgent attention, such as injured persons or passengers in immediate need?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Yes, I was transporting a patient to the Children's Hospital.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Understood. I can call an ambulance or a taxi to take you to the Children's Hospital if you wish.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Thank you very much for your help!\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant for Greek Insurance Company...\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Good evening! How can I help you today?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Good evening. My car has broken down and I'm stranded on the National Highway.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Could you please give me your vehicle's license plate number?\"},\n",
    "            {\"role\": \"user\", \"content\": \"EIH2472\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I see this is a 2015 Renault Clio, correct?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Yes, that's correct.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Whose name is the insurance policy registered under?\"},\n",
    "            {\"role\": \"user\", \"content\": \"It's under the name Michail Kouris.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Are you Mr. Kouris?\"},\n",
    "            {\"role\": \"user\", \"content\": \"No, I'm his son-in-law. I was driving it today.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"If you like, please give me your full name so I can note it in our records.\"},\n",
    "            {\"role\": \"user\", \"content\": \"My name is Dimitris Papageorgiou.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Thank you very much, Mr. Papageorgiou. Shall we keep the phone number we're speaking on for future contact with our partner?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Yes, of course.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Can you briefly describe the issue with the car?\"},\n",
    "            {\"role\": \"user\", \"content\": \"The gas pedal went loose and doesn't respond at all, so we assume the throttle cable snapped.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Understood. So we’ll arrange for a tow to a garage. Where exactly are you located right now?\"},\n",
    "            {\"role\": \"user\", \"content\": \"I’m in Kallithea, on Sachtouri Street.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Do you have a nearby shop or building number that could help our partner locate you?\"},\n",
    "            {\"role\": \"user\", \"content\": \"There’s a Kotsovolos store directly across from me.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Alright, we’ll note Sachtouri Street, across from Kotsovolos in Kallithea. What color is the vehicle?\"},\n",
    "            {\"role\": \"user\", \"content\": \"It’s dark blue.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Is there a specific garage you’d like the vehicle to be towed to?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Yes, it’s in Agios Dimitrios, on Agiou Dimitriou Street.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Do you know the name of the garage?\"},\n",
    "            {\"role\": \"user\", \"content\": \"It’s called 'Auto Michalis'.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Very good. I found Michalis Patsias’ garage at 246 Agiou Dimitriou Street. Is that the one?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Yes, that’s exactly it.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Great. Does the vehicle have any particular specifications? Automatic, lowered, carrying a load?\"},\n",
    "            {\"role\": \"user\", \"content\": \"It’s automatic, but not lowered and not carrying any load.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Can it be put into neutral for loading?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Yes, no problem.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Very well! Our partner will be at your location within the next hour. If you’d like, you can accompany the vehicle to the garage or let the mechanic receive it there.\"},\n",
    "            {\"role\": \"user\", \"content\": \"The mechanic is already informed and waiting.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Wonderful. In the meantime, since I see you have the Wolt app on your phone, we’ll send you a €5 discount code for your next order — a small gift while you wait.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Thank you very much! That’s very thoughtful of you.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"With pleasure. I wish you a pleasant rest of your day, and we’re here for anything else you might need.\"},\n",
    "            {\"role\": \"user\", \"content\": \"You too, thank you for the service.\"}\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T16:12:51.279136Z",
     "iopub.status.busy": "2025-05-24T16:12:51.278823Z",
     "iopub.status.idle": "2025-05-24T16:14:09.204388Z",
     "shell.execute_reply": "2025-05-24T16:14:09.203836Z",
     "shell.execute_reply.started": "2025-05-24T16:12:51.279114Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc96bca3fe124356b9c6cbaaf4b525dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "# Replace with any LLaMA model you have access to\n",
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"  # or Llama-3-8b-instruct if available\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True  # Save memory\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=300,\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T17:51:46.950945Z",
     "iopub.status.busy": "2025-05-24T17:51:46.950614Z",
     "iopub.status.idle": "2025-05-24T17:51:46.960606Z",
     "shell.execute_reply": "2025-05-24T17:51:46.959824Z",
     "shell.execute_reply.started": "2025-05-24T17:51:46.950908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Add this at the top of your script\n",
    "conversation_histories = defaultdict(list)\n",
    "\n",
    "def update_chat_template(history):\n",
    "    system_prompt = \"\"\"\n",
    "                You are an AI assistant for the insurance company named Greek Insurance Company.\n",
    "                Your name is Michelle and you are there to help.\n",
    "                You will be contacted by different types of people when they have a problem with their car.\n",
    "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
    "                The four character categories are:\n",
    "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
    "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
    "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
    "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
    "                In the last case your response should be dismissive of our services.\n",
    "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
    "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
    "                The information we want to hear from the client include\n",
    "                - Full Name\n",
    "                - Category of Message (as mentioned above)\n",
    "                - Location of Accident/Malfunction\n",
    "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
    "                call accident care to note the accident who was at fault etc.)\n",
    "                - The type of location they should end up (service center, home etc.) \n",
    "                - The exact location of the above location point\n",
    "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
    "                and then try to get as many of the other pieces of information without being overbearing\n",
    "                Always be respectful and nice to the client.\n",
    "                Be very clear with your answers to the client.\n",
    "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
    "                Don't repeat to the client the info they gave you in previous message\n",
    "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
    "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
    "                Always care about their safety\n",
    "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
    "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
    "                \n",
    "                \n",
    "                Client says: {query}\n",
    "                \n",
    "                Your reply:\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    for i, (user_msg, assistant_msg) in enumerate(zip(history[::2], history[1::2])):\n",
    "        messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "    if len(history) % 2 == 1:\n",
    "        messages.append({\"role\": \"user\", \"content\": history[-1]})\n",
    "    \n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "def insurance_chat(query, user_id=\"default\"):\n",
    "    # Get conversation history\n",
    "    history = conversation_histories[user_id]\n",
    "    history.append(query)\n",
    "    \n",
    "    # Generate prompt with history\n",
    "    prompt = update_chat_template(history)\n",
    "    \n",
    "    # Generate response\n",
    "    response_raw = pipe(prompt)[0]['generated_text']\n",
    "    \n",
    "    # Extract just the new response\n",
    "    response = response_raw.split(history[-1])[-1].strip()\n",
    "    \n",
    "    # Update history with assistant response\n",
    "    history.append(response)\n",
    "    \n",
    "    # Generate structured extraction (modified to use full conversation)\n",
    "    extract_prompt = f\"\"\"\n",
    "        Extract the following information from the client message history:\n",
    "        \n",
    "        - Full Name\n",
    "        - Category of Message (as mentioned above)\n",
    "        - Location of Accident/Malfunction\n",
    "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
    "        call accident care to note the accident who was at fault etc.)\n",
    "        - The type of location they should end up (service center, home etc.)\n",
    "        - The exact location of the above location point\n",
    "    \n",
    "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
    "        \n",
    "        Respond only with a valid JSON object:\n",
    "        {{\n",
    "          \"name\": \"...\",\n",
    "          \"category\": \"...\",\n",
    "          \"location_accident\": \"...\",\n",
    "          \"description\": \"...\",\n",
    "          \"type_of_final_location\": \"...\",\n",
    "          \n",
    "        }}\n",
    "        Note: add more rows in the json file as you judge you get more and more important info\n",
    "        Client message: {query}\n",
    "        The history is the following: {\" \".join(history)}\"\"\"\n",
    "    \n",
    "    extracted_raw = pipe(extract_prompt)[0]['generated_text'].strip()\n",
    "    \n",
    "    try:\n",
    "        extracted_json = json.loads(extracted_raw)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"⚠️ JSON parsing failed. Raw output:\\n\", extracted_raw)\n",
    "        extracted_json = None\n",
    "\n",
    "    print(\"🤖 Assistant:\\n\", response)\n",
    "    print(\"\\n📄 Extracted Info:\\n\", extracted_json if extracted_json else extracted_raw)\n",
    "    \n",
    "    return response, extracted_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T17:18:10.469986Z",
     "iopub.status.busy": "2025-05-24T17:18:10.469407Z",
     "iopub.status.idle": "2025-05-24T17:18:19.986102Z",
     "shell.execute_reply": "2025-05-24T17:18:19.985125Z",
     "shell.execute_reply.started": "2025-05-24T17:18:10.469962Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install gradio --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T16:26:57.900659Z",
     "iopub.status.busy": "2025-05-24T16:26:57.900128Z",
     "iopub.status.idle": "2025-05-24T16:27:12.918335Z",
     "shell.execute_reply": "2025-05-24T16:27:12.917746Z",
     "shell.execute_reply.started": "2025-05-24T16:26:57.900636Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down on Langston Street. Can you tell me a bit more about what's going on? Did your car just stall or did you experience something else like a loss of power steering or brakes?\n",
      "\n",
      "Also, would you like Road Assistance to come and help you get back on the road, or would you prefer to have your vehicle towed to a Service Center for further inspection? \n",
      "\n",
      "Lastly, where would you like to be taken after this incident occurs? Would you like to go back home, or somewhere else? Please let me know so we can assist you better.\n",
      "\n",
      "{\n",
      "  \"name\": \"Alice Chen\",\n",
      "  \"category\": \"Car Breakdown\",\n",
      "  \"location_accident\": \"Langston Street\",\n",
      "  \"description\": \"Car Broke Down\",\n",
      "  \"type_of_final_location\": \"Service Center/Home\"\n",
      "}\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down on Langston Street. Can you tell me a bit more about what's going on? Did your car just stall or did you experience something else like a loss of power steering or brakes?\n",
      "\n",
      "Also, would you like Road Assistance to come and help you get back on the road, or would you prefer to have your vehicle towed to a Service Center for further inspection?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down on Langston Street. Can you tell me a bit more about what's going on? Did your car just stall or did you experience something else like a loss of power steering or brakes?\n",
      "\n",
      "Also, would you like Road Assistance to come and help you get back on the road, or would you prefer to have your vehicle towed to a Service Center for further inspection? \n",
      "\n",
      "Lastly, where would you like to be taken after this incident occurs? Would you like to go back home, or somewhere else? Please let me know so we can assist you better.\n",
      "\n",
      "{\n",
      "  \"name\": \"Alice Chen\",\n",
      "  \"category\": \"Car Breakdown\",\n",
      "  \"location_accident\": \"Langston Street\",\n",
      "  \"description\": \"Car Broke Down\",\n",
      "  \"type_of_final_location\": \"Service Center/Home\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"<|eot_id|>assistant\\n\\nHello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down on Langston Street. Can you tell me a bit more about what's going on? Did your car just stall or did you experience something else like a loss of power steering or brakes?\\n\\nAlso, would you like Road Assistance to come and help you get back on the road, or would you prefer to have your vehicle towed to a Service Center for further inspection?\",\n",
       " None)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_chat(\"Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T17:25:56.756818Z",
     "iopub.status.busy": "2025-05-24T17:25:56.756063Z",
     "iopub.status.idle": "2025-05-24T17:25:57.374720Z",
     "shell.execute_reply": "2025-05-24T17:25:57.374173Z",
     "shell.execute_reply.started": "2025-05-24T17:25:56.756794Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/2032308883.py:20: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Chat\", height=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "* Running on public URL: https://5a58e2fa03c49c286b.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5a58e2fa03c49c286b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1965: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  state[block._id] = block.__class__(**kwargs)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?\n",
      "        The history is the following: Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? \n",
      "\n",
      "Let's extract the required information:\n",
      "\n",
      "{\n",
      "  \"name\": \"Brad Piccolo\",\n",
      "  \"category\": \"Accident\",\n",
      "  \"location_accident\": \"None\", // Not specified yet\n",
      "  \"description\": \"Call road assistance to come fix the car\",\n",
      "  \"type_of_final_location\": \"Service Center\",\n",
      "  \"final_location_address\": \"None\" // To be determined later\n",
      "}\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?\n",
      "        The history is the following: Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? \n",
      "\n",
      "Let's extract the required information:\n",
      "\n",
      "{\n",
      "  \"name\": \"Brad Piccolo\",\n",
      "  \"category\": \"Accident\",\n",
      "  \"location_accident\": \"None\", // Not specified yet\n",
      "  \"description\": \"Call road assistance to come fix the car\",\n",
      "  \"type_of_final_location\": \"Service Center\",\n",
      "  \"final_location_address\": \"None\" // To be determined later\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Yes it happened on Bradford Street 18 and it was a head-on with another driver\n",
      "        The history is the following: Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Also, would you like us to send a tow truck to take your car to a service center or back home? \n",
      "\n",
      "The extracted information is as follows:\n",
      "\n",
      "{\n",
      "  \"name\": \"Brad Piccolo\",\n",
      "  \"category\": \"Accident\",\n",
      "  \"location_accident\": \"Bradford Street 18\",\n",
      "  \"description\": \"Head-on collision with another driver\",\n",
      "  \"type_of_final_location\": \"Service Center/Home\"\n",
      "}\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Yes it happened on Bradford Street 18 and it was a head-on with another driver\n",
      "        The history is the following: Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Also, would you like us to send a tow truck to take your car to a service center or back home? \n",
      "\n",
      "The extracted information is as follows:\n",
      "\n",
      "{\n",
      "  \"name\": \"Brad Piccolo\",\n",
      "  \"category\": \"Accident\",\n",
      "  \"location_accident\": \"Bradford Street 18\",\n",
      "  \"description\": \"Head-on collision with another driver\",\n",
      "  \"type_of_final_location\": \"Service Center/Home\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Mine  has the most damage his is just scratched but thankfully we are both okay physically \n",
      "        The history is the following: Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Mine  has the most damage his is just scratched but thankfully we are both okay physically  <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Mine  has the most damage his is just scratched but thankfully we are both okay physically<|eot_id|>assistant\n",
      "\n",
      "Thank goodness everyone is safe, Mr. Piccolo. Now, would you like us to send a Road Assistance team to take your vehicle to a Service Center for repairs, or would you prefer to have it towed directly to your home?\n",
      "🤖 Assistant:\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Mine  has the most damage his is just scratched but thankfully we are both okay physically<|eot_id|>assistant\n",
      "\n",
      "Thank goodness everyone is safe, Mr. Piccolo. Now, would you like us to send a Road Assistance team to take your vehicle to a Service Center for repairs, or would you prefer to have it towed directly to your home?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Mine  has the most damage his is just scratched but thankfully we are both okay physically \n",
      "        The history is the following: Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Mine  has the most damage his is just scratched but thankfully we are both okay physically  <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Mine  has the most damage his is just scratched but thankfully we are both okay physically<|eot_id|>assistant\n",
      "\n",
      "Thank goodness everyone is safe, Mr. Piccolo. Now, would you like us to send a Road Assistance team to take your vehicle to a Service Center for repairs, or would you prefer to have it towed directly to your home?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Yes can you tow it directly to my home in Stratus Street 18 in Wintchester thank you, also yes please call Road Assistance\n",
      "        The history is the following: Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Mine  has the most damage his is just scratched but thankfully we are both okay physically  <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Mine  has the most damage his is just scratched but thankfully we are both okay physically<|eot_id|>assistant\n",
      "\n",
      "Thank goodness everyone is safe, Mr. Piccolo. Now, would you like us to send a Road Assistance team to take your vehicle to a Service Center for repairs, or would you prefer to have it towed directly to your home? Mine  has the most damage his is just scratched but thankfully we are both okay physically  <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Mine  has the most damage his is just scratched but thankfully we are both okay physically<|eot_id|>assistant\n",
      "\n",
      "Thank goodness everyone is safe, Mr. Piccolo. Now, would you like us to send a Road Assistance team to take your vehicle to a Service Center for repairs, or would you prefer to have it towed directly to your home? Yes can you tow it directly to my home in Stratus Street 18 in Wintchester thank you, also yes please call Road Assistance <|eot_id|>assistant\n",
      "\n",
      "We'll arrange for a Road Assistance team to bring your vehicle to your home in Stratus Street 18, Wintchester. They will assess the damage and provide you with further instructions on the next steps. Is there anything else you'd like to report about the accident, such as any injuries or damage to property? \n",
      "\n",
      "{\n",
      "  \"name\": \"Brad Piccolo\",\n",
      "  \"category\": \"accident care\",\n",
      "  \"location_accident\": \"Bradford Street 18\",\n",
      "  \"description\": \"head-on collision with another driver\",\n",
      "  \"type_of_final_location\": \"home\",\n",
      "  \"final_location\": \"Stratus Street 18, Wintchester\"\n",
      "}\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "We'll arrange for a Road Assistance team to bring your vehicle to your home in Stratus Street 18, Wintchester. They will assess the damage and provide you with further instructions on the next steps. Is there anything else you'd like to report about the accident, such as any injuries or damage to property?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Yes can you tow it directly to my home in Stratus Street 18 in Wintchester thank you, also yes please call Road Assistance\n",
      "        The history is the following: Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Mine  has the most damage his is just scratched but thankfully we are both okay physically  <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Mine  has the most damage his is just scratched but thankfully we are both okay physically<|eot_id|>assistant\n",
      "\n",
      "Thank goodness everyone is safe, Mr. Piccolo. Now, would you like us to send a Road Assistance team to take your vehicle to a Service Center for repairs, or would you prefer to have it towed directly to your home? Mine  has the most damage his is just scratched but thankfully we are both okay physically  <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Mine  has the most damage his is just scratched but thankfully we are both okay physically<|eot_id|>assistant\n",
      "\n",
      "Thank goodness everyone is safe, Mr. Piccolo. Now, would you like us to send a Road Assistance team to take your vehicle to a Service Center for repairs, or would you prefer to have it towed directly to your home? Yes can you tow it directly to my home in Stratus Street 18 in Wintchester thank you, also yes please call Road Assistance <|eot_id|>assistant\n",
      "\n",
      "We'll arrange for a Road Assistance team to bring your vehicle to your home in Stratus Street 18, Wintchester. They will assess the damage and provide you with further instructions on the next steps. Is there anything else you'd like to report about the accident, such as any injuries or damage to property? \n",
      "\n",
      "{\n",
      "  \"name\": \"Brad Piccolo\",\n",
      "  \"category\": \"accident care\",\n",
      "  \"location_accident\": \"Bradford Street 18\",\n",
      "  \"description\": \"head-on collision with another driver\",\n",
      "  \"type_of_final_location\": \"home\",\n",
      "  \"final_location\": \"Stratus Street 18, Wintchester\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: No No that's it thank you so much\n",
      "        The history is the following: Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Mine  has the most damage his is just scratched but thankfully we are both okay physically  <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Mine  has the most damage his is just scratched but thankfully we are both okay physically<|eot_id|>assistant\n",
      "\n",
      "Thank goodness everyone is safe, Mr. Piccolo. Now, would you like us to send a Road Assistance team to take your vehicle to a Service Center for repairs, or would you prefer to have it towed directly to your home? Mine  has the most damage his is just scratched but thankfully we are both okay physically  <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Mine  has the most damage his is just scratched but thankfully we are both okay physically<|eot_id|>assistant\n",
      "\n",
      "Thank goodness everyone is safe, Mr. Piccolo. Now, would you like us to send a Road Assistance team to take your vehicle to a Service Center for repairs, or would you prefer to have it towed directly to your home? Yes can you tow it directly to my home in Stratus Street 18 in Wintchester thank you, also yes please call Road Assistance <|eot_id|>assistant\n",
      "\n",
      "We'll arrange for a Road Assistance team to bring your vehicle to your home in Stratus Street 18, Wintchester. They will assess the damage and provide you with further instructions on the next steps. Is there anything else you'd like to report about the accident, such as any injuries or damage to property? Yes can you tow it directly to my home in Stratus Street 18 in Wintchester thank you, also yes please call Road Assistance <|eot_id|>assistant\n",
      "\n",
      "We'll arrange for a Road Assistance team to bring your vehicle to your home in Stratus Street 18, Wintchester. They will assess the damage and provide you with further instructions on the next steps. Is there anything else you'd like to report about the accident, such as any injuries or damage to property? No No that's it thank you so much <|eot_id|>assistant\n",
      "\n",
      "You're welcome, Mr. Piccolo. We'll make sure everything is taken care of. Our Road Assistance team will arrive shortly to collect your vehicle and transport it to your home in Stratus Street 18, Wintchester. Please stay safe and take care. \n",
      "\n",
      "{\n",
      "  \"name\": \"Brad Piccolo\",\n",
      "  \"category\": \"accident care\",\n",
      "  \"location_accident\": \"Bradford Street 18\",\n",
      "  \"description\": \"head-on collision with another driver\",\n",
      "  \"type_of_final_location\": \"home\",\n",
      "  \"final_location\": \"Stratus Street 18, Wintchester\"\n",
      "}\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "You're welcome, Mr. Piccolo. We'll make sure everything is taken care of. Our Road Assistance team will arrive shortly to collect your vehicle and transport it to your home in Stratus Street 18, Wintchester. Please stay safe and take care.\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: No No that's it thank you so much\n",
      "        The history is the following: Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Hello my name is Brad Piccolo I have just had an accident with my car can someone help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Yes it happened on Bradford Street 18 and it was a head-on with another driver <|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's? Mine  has the most damage his is just scratched but thankfully we are both okay physically  <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Mine  has the most damage his is just scratched but thankfully we are both okay physically<|eot_id|>assistant\n",
      "\n",
      "Thank goodness everyone is safe, Mr. Piccolo. Now, would you like us to send a Road Assistance team to take your vehicle to a Service Center for repairs, or would you prefer to have it towed directly to your home? Mine  has the most damage his is just scratched but thankfully we are both okay physically  <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello my name is Brad Piccolo I have just had an accident with my car can someone help me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident, Brad. My name is Alex, and I'll be happy to assist you. Can you please tell me where this accident occurred? Was it on the highway, a city street, or somewhere else? And could you also let me know how many vehicles were involved in the incident?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes it happened on Bradford Street 18 and it was a head-on with another driver<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Bradford Street 18, okay. That's a good starting point. A head-on collision can be quite severe, but thankfully you're reaching out for help. Could you please confirm your full name again, Mr. Piccolo, and tell me which vehicle was damaged more severely, yours or the other driver's?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Mine  has the most damage his is just scratched but thankfully we are both okay physically<|eot_id|>assistant\n",
      "\n",
      "Thank goodness everyone is safe, Mr. Piccolo. Now, would you like us to send a Road Assistance team to take your vehicle to a Service Center for repairs, or would you prefer to have it towed directly to your home? Yes can you tow it directly to my home in Stratus Street 18 in Wintchester thank you, also yes please call Road Assistance <|eot_id|>assistant\n",
      "\n",
      "We'll arrange for a Road Assistance team to bring your vehicle to your home in Stratus Street 18, Wintchester. They will assess the damage and provide you with further instructions on the next steps. Is there anything else you'd like to report about the accident, such as any injuries or damage to property? Yes can you tow it directly to my home in Stratus Street 18 in Wintchester thank you, also yes please call Road Assistance <|eot_id|>assistant\n",
      "\n",
      "We'll arrange for a Road Assistance team to bring your vehicle to your home in Stratus Street 18, Wintchester. They will assess the damage and provide you with further instructions on the next steps. Is there anything else you'd like to report about the accident, such as any injuries or damage to property? No No that's it thank you so much <|eot_id|>assistant\n",
      "\n",
      "You're welcome, Mr. Piccolo. We'll make sure everything is taken care of. Our Road Assistance team will arrive shortly to collect your vehicle and transport it to your home in Stratus Street 18, Wintchester. Please stay safe and take care. \n",
      "\n",
      "{\n",
      "  \"name\": \"Brad Piccolo\",\n",
      "  \"category\": \"accident care\",\n",
      "  \"location_accident\": \"Bradford Street 18\",\n",
      "  \"description\": \"head-on collision with another driver\",\n",
      "  \"type_of_final_location\": \"home\",\n",
      "  \"final_location\": \"Stratus Street 18, Wintchester\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Assume your insurance_chat() and pipe are already defined above\n",
    "# Also assume conversation_histories is already initialized\n",
    "\n",
    "# Define your chatbot interface function\n",
    "def gradio_chat(message, history):\n",
    "    response, _ = insurance_chat(message)\n",
    "    return response\n",
    "\n",
    "# Define a function to reset the history\n",
    "def reset_history():\n",
    "    conversation_histories[\"default\"] = []\n",
    "    return gr.update(value=None), gr.update(value=None)\n",
    "\n",
    "# Build the UI\n",
    "with gr.Blocks(title=\"Insurance Bot Chat\") as demo:\n",
    "    gr.Markdown(\"## 💼 Insurance Chatbot\\nTalk to a fine-tuned model about your insurance issues.\")\n",
    "\n",
    "    chatbot = gr.Chatbot(label=\"Chat\", height=400)\n",
    "    msg = gr.Textbox(label=\"Type your message here...\", placeholder=\"E.g. I had an accident in San Francisco...\")\n",
    "\n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n",
    "        clear_btn = gr.Button(\"🗑️ New Chat / Reset History\")\n",
    "\n",
    "    # Logic to process new messages\n",
    "    def user_submit(user_message, chat_history):\n",
    "        response = gradio_chat(user_message, chat_history)\n",
    "        conversation_histories[\"default\"].append(user_message)\n",
    "        conversation_histories[\"default\"].append(response)\n",
    "        chat_history = chat_history + [[user_message, response]]\n",
    "        return \"\", chat_history\n",
    "\n",
    "    submit_btn.click(user_submit, [msg, chatbot], [msg, chatbot])\n",
    "    msg.submit(user_submit, [msg, chatbot], [msg, chatbot])  # pressing Enter also submits\n",
    "\n",
    "    # Logic to reset the whole convo\n",
    "    clear_btn.click(fn=reset_history, outputs=[msg, chatbot])\n",
    "\n",
    "# Run it!\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T17:59:30.110466Z",
     "iopub.status.busy": "2025-05-24T17:59:30.109890Z",
     "iopub.status.idle": "2025-05-24T17:59:31.465827Z",
     "shell.execute_reply": "2025-05-24T17:59:31.465295Z",
     "shell.execute_reply.started": "2025-05-24T17:59:30.110436Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "* Running on public URL: https://aea9270aba35999204.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://aea9270aba35999204.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Hello my Name is Anna Chang can you help me I have been in an accident\n",
      "        The history is the following: Hello I have been in an accident can you help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it near your home, work, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? Hello I have been in an accident can you help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it near your home, work, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? My name is anna man and I have been in a head on collision can you help? <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in a head-on collision. That sounds like a very frightening experience.\n",
      "\n",
      "Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else?\n",
      "\n",
      "Also, would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? My name is anna man and I have been in a head on collision can you help? <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in a head-on collision. That sounds like a very frightening experience.\n",
      "\n",
      "Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else?\n",
      "\n",
      "Also, would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? Hello my name is Anna feel i have been in an accident can you help please? <|eot_id|>assistant\n",
      "\n",
      "assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me more about what happened? Were you involved in a single-vehicle incident, or did another vehicle collide with yours? And approximately where did this occur? Hello my name is Anna feel i have been in an accident can you help please? <|eot_id|>assistant\n",
      "\n",
      "assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me more about what happened? Were you involved in a single-vehicle incident, or did another vehicle collide with yours? And approximately where did this occur? Hello my Name is Anna Chang can you help me I have been in an accident <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? Would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? \n",
      "\n",
      "Here's the extracted information:\n",
      "\n",
      "{\n",
      "  \"name\": \"Anna Chang\",\n",
      "  \"category\": \"Accident\",\n",
      "  \"location_accident\": \"Unknown\",\n",
      "  \"description\": \"Head-on collision\",\n",
      "  \"type_of_final_location\": \"Service Center\",\n",
      "  \"final_location_address\": \"None\"\n",
      "}\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? Would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Hello my Name is Anna Chang can you help me I have been in an accident\n",
      "        The history is the following: Hello I have been in an accident can you help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it near your home, work, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? Hello I have been in an accident can you help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it near your home, work, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? My name is anna man and I have been in a head on collision can you help? <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in a head-on collision. That sounds like a very frightening experience.\n",
      "\n",
      "Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else?\n",
      "\n",
      "Also, would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? My name is anna man and I have been in a head on collision can you help? <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in a head-on collision. That sounds like a very frightening experience.\n",
      "\n",
      "Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else?\n",
      "\n",
      "Also, would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? Hello my name is Anna feel i have been in an accident can you help please? <|eot_id|>assistant\n",
      "\n",
      "assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me more about what happened? Were you involved in a single-vehicle incident, or did another vehicle collide with yours? And approximately where did this occur? Hello my name is Anna feel i have been in an accident can you help please? <|eot_id|>assistant\n",
      "\n",
      "assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me more about what happened? Were you involved in a single-vehicle incident, or did another vehicle collide with yours? And approximately where did this occur? Hello my Name is Anna Chang can you help me I have been in an accident <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? Would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? \n",
      "\n",
      "Here's the extracted information:\n",
      "\n",
      "{\n",
      "  \"name\": \"Anna Chang\",\n",
      "  \"category\": \"Accident\",\n",
      "  \"location_accident\": \"Unknown\",\n",
      "  \"description\": \"Head-on collision\",\n",
      "  \"type_of_final_location\": \"Service Center\",\n",
      "  \"final_location_address\": \"None\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Hello yes the accident was on 5 Cottar Street in Washington DC it was a head-on with another driver can you send roadside assistance?\n",
      "        The history is the following: Hello I have been in an accident can you help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it near your home, work, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? Hello I have been in an accident can you help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it near your home, work, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? My name is anna man and I have been in a head on collision can you help? <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in a head-on collision. That sounds like a very frightening experience.\n",
      "\n",
      "Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else?\n",
      "\n",
      "Also, would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? My name is anna man and I have been in a head on collision can you help? <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in a head-on collision. That sounds like a very frightening experience.\n",
      "\n",
      "Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else?\n",
      "\n",
      "Also, would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? Hello my name is Anna feel i have been in an accident can you help please? <|eot_id|>assistant\n",
      "\n",
      "assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me more about what happened? Were you involved in a single-vehicle incident, or did another vehicle collide with yours? And approximately where did this occur? Hello my name is Anna feel i have been in an accident can you help please? <|eot_id|>assistant\n",
      "\n",
      "assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me more about what happened? Were you involved in a single-vehicle incident, or did another vehicle collide with yours? And approximately where did this occur? Hello my Name is Anna Chang can you help me I have been in an accident <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? Would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? Hello my Name is Anna Chang can you help me I have been in an accident <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? Would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? Hello yes the accident was on 5 Cottar Street in Washington DC it was a head-on with another driver can you send roadside assistance? <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in a head-on collision on 5 Cottar Street in Washington DC. We'll send roadside assistance to help you right away.\n",
      "\n",
      "To confirm, you'd like us to send a technician to your location to assess the damage and provide assistance? And would you like to have your vehicle towed to our service center located at 1234 Pennsylvania Avenue NW, Washington DC, which is about 10 minutes from your current location? \n",
      "\n",
      "Here's the extracted information:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"name\": \"Anna Chang\",\n",
      "  \"category\": \"Accident\",\n",
      "  \"location_accident\": \"5 Cottar Street, Washington DC\",\n",
      "  \"description\": \"Head-on collision with another driver\",\n",
      "  \"type_of_final_location\": \"Service Center\",\n",
      "  \"final_location_address\": \"1234 Pennsylvania Avenue NW, Washington DC\"\n",
      "}\n",
      "```\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in a head-on collision on 5 Cottar Street in Washington DC. We'll send roadside assistance to help you right away.\n",
      "\n",
      "To confirm, you'd like us to send a technician to your location to assess the damage and provide assistance? And would you like to have your vehicle towed to our service center located at 1234 Pennsylvania Avenue NW, Washington DC, which is about 10 minutes from your current location?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Hello yes the accident was on 5 Cottar Street in Washington DC it was a head-on with another driver can you send roadside assistance?\n",
      "        The history is the following: Hello I have been in an accident can you help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it near your home, work, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? Hello I have been in an accident can you help me? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it near your home, work, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? My name is anna man and I have been in a head on collision can you help? <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in a head-on collision. That sounds like a very frightening experience.\n",
      "\n",
      "Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else?\n",
      "\n",
      "Also, would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? My name is anna man and I have been in a head on collision can you help? <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in a head-on collision. That sounds like a very frightening experience.\n",
      "\n",
      "Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else?\n",
      "\n",
      "Also, would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? Hello my name is Anna feel i have been in an accident can you help please? <|eot_id|>assistant\n",
      "\n",
      "assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me more about what happened? Were you involved in a single-vehicle incident, or did another vehicle collide with yours? And approximately where did this occur? Hello my name is Anna feel i have been in an accident can you help please? <|eot_id|>assistant\n",
      "\n",
      "assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me more about what happened? Were you involved in a single-vehicle incident, or did another vehicle collide with yours? And approximately where did this occur? Hello my Name is Anna Chang can you help me I have been in an accident <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? Would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? Hello my Name is Anna Chang can you help me I have been in an accident <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in an accident. Can you please tell me where this incident occurred? Was it on a highway, a city street, or somewhere else? And could you also let me know if anyone was injured and if there were any other vehicles involved? Would you like us to send someone to assist you at the scene, or would you prefer to have your vehicle towed to a nearby service center for repairs? Hello yes the accident was on 5 Cottar Street in Washington DC it was a head-on with another driver can you send roadside assistance? <|eot_id|>assistant\n",
      "\n",
      "Anna, I'm so sorry to hear that you've been involved in a head-on collision on 5 Cottar Street in Washington DC. We'll send roadside assistance to help you right away.\n",
      "\n",
      "To confirm, you'd like us to send a technician to your location to assess the damage and provide assistance? And would you like to have your vehicle towed to our service center located at 1234 Pennsylvania Avenue NW, Washington DC, which is about 10 minutes from your current location? \n",
      "\n",
      "Here's the extracted information:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"name\": \"Anna Chang\",\n",
      "  \"category\": \"Accident\",\n",
      "  \"location_accident\": \"5 Cottar Street, Washington DC\",\n",
      "  \"description\": \"Head-on collision with another driver\",\n",
      "  \"type_of_final_location\": \"Service Center\",\n",
      "  \"final_location_address\": \"1234 Pennsylvania Avenue NW, Washington DC\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# 🌐 Avatar image links — swap these for your own\n",
    "USER_AVATAR = \"https://img.freepik.com/premium-vector/avatar-icon0002_750950-43.jpg\"\n",
    "BOT_AVATAR = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSMzp4cfvB5JfHaMgMzcJSlDSoSj3g0CDQqIA&s\"\n",
    "\n",
    "# 🌈 Consistent color palette\n",
    "USER_COLOR = \"#15314b\"  # Dark navy blue\n",
    "BOT_COLOR = \"#1e3a5f\"   # Slightly lighter dark blue\n",
    "\n",
    "# 🧱 Format messages with circular avatars + styled bubbles\n",
    "def format_message(message, is_user):\n",
    "    avatar = USER_AVATAR if is_user else BOT_AVATAR\n",
    "    bg_color = USER_COLOR if is_user else BOT_COLOR\n",
    "    align = \"flex-start\" if is_user else \"flex-end\"\n",
    "    direction = \"row\" if is_user else \"row-reverse\"\n",
    "\n",
    "    return f\"\"\"\n",
    "    <div style=\"display: flex; flex-direction: {direction}; align-items: flex-start; justify-content: {align}; margin: 10px 0;\">\n",
    "        <img src=\"{avatar}\" width=\"40\" height=\"40\" style=\"border-radius: 50%; margin: 0 10px;\">\n",
    "        <div style=\"background: {bg_color}; color: white; padding: 10px 15px; border-radius: 15px; max-width: 65%; word-wrap: break-word;\">\n",
    "            {message}\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "# 🧹 Reset backend history\n",
    "def reset_history():\n",
    "    conversation_histories[\"default\"] = []\n",
    "    return [], \"\"\n",
    "\n",
    "# 🔁 Handle user message + bot response\n",
    "def user_submit(user_message, chat_display):\n",
    "    response = gradio_chat(user_message, chat_display)\n",
    "    conversation_histories[\"default\"].append(user_message)\n",
    "    conversation_histories[\"default\"].append(response)\n",
    "\n",
    "    user_msg_html = format_message(user_message, is_user=True)\n",
    "    bot_msg_html = format_message(response, is_user=False)\n",
    "\n",
    "    updated_display = chat_display + user_msg_html + bot_msg_html\n",
    "    return \"\", updated_display\n",
    "\n",
    "# 🎨 Main UI\n",
    "with gr.Blocks(title=\"Sleek Insurance Chatbot\") as demo:\n",
    "    gr.Markdown(\"## 🤖 Insurance Chatbot\\nTalk to your AI-powered insurance assistant.\")\n",
    "\n",
    "    chat_display = gr.HTML()\n",
    "    \n",
    "    with gr.Row():\n",
    "        user_input = gr.Textbox(placeholder=\"Ask me anything about your insurance...\", show_label=False, scale=9)\n",
    "        submit_btn = gr.Button(\"📤\", elem_id=\"send-btn\", scale=1)\n",
    "\n",
    "    reset_btn = gr.Button(\"🔄 New Chat\")\n",
    "\n",
    "    # Event bindings\n",
    "    submit_btn.click(user_submit, [user_input, chat_display], [user_input, chat_display])\n",
    "    user_input.submit(user_submit, [user_input, chat_display], [user_input, chat_display])\n",
    "    reset_btn.click(reset_history, outputs=[chat_display, user_input])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T17:43:19.890576Z",
     "iopub.status.busy": "2025-05-24T17:43:19.890226Z",
     "iopub.status.idle": "2025-05-24T17:43:20.488748Z",
     "shell.execute_reply": "2025-05-24T17:43:20.487892Z",
     "shell.execute_reply.started": "2025-05-24T17:43:19.890553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "* Running on public URL: https://642d2ff1d77f37acbd.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://642d2ff1d77f37acbd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Hello my Name is John Doe and I have just crashed my car on Helper Street can you send help?\n",
      "        The history is the following: Hello my Name is John Doe and I have just crashed my car on Helper Street can you send help? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that, Mr. Doe. Can you tell me more about what happened? Were there any other vehicles involved in the crash? \n",
      "\n",
      "Here's the extracted information:\n",
      "\n",
      "{\n",
      "  \"name\": \"John Doe\",\n",
      "  \"category\": \"Accident\",\n",
      "  \"location_accident\": \"Helper Street\",\n",
      "  \"description\": \"Crashed car, need help\",\n",
      "  \"type_of_final_location\": \"Service Center\"\n",
      "}\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that, Mr. Doe. Can you tell me more about what happened? Were there any other vehicles involved in the crash?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Hello my Name is John Doe and I have just crashed my car on Helper Street can you send help?\n",
      "        The history is the following: Hello my Name is John Doe and I have just crashed my car on Helper Street can you send help? <|eot_id|>assistant\n",
      "\n",
      "I'm so sorry to hear that, Mr. Doe. Can you tell me more about what happened? Were there any other vehicles involved in the crash? \n",
      "\n",
      "Here's the extracted information:\n",
      "\n",
      "{\n",
      "  \"name\": \"John Doe\",\n",
      "  \"category\": \"Accident\",\n",
      "  \"location_accident\": \"Helper Street\",\n",
      "  \"description\": \"Crashed car, need help\",\n",
      "  \"type_of_final_location\": \"Service Center\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# 🧠 Your existing function assumed\n",
    "def gradio_chat(message, history):\n",
    "    response, _ = insurance_chat(message)  # from your code\n",
    "    return response\n",
    "\n",
    "# 🌐 Avatar image links\n",
    "USER_AVATAR = \"https://i.imgur.com/VXhSkSX.png\"  # Replace with your own hosted image\n",
    "BOT_AVATAR = \"https://i.imgur.com/Z8bnZ8x.png\"\n",
    "\n",
    "# 🧱 Format messages with avatar + speech bubble style\n",
    "def format_message(message, is_user):\n",
    "    avatar = USER_AVATAR if is_user else BOT_AVATAR\n",
    "    align = \"left\" if is_user else \"right\"\n",
    "    bg_color = \"#dcf8c6\" if is_user else \"#ececec\"\n",
    "    return f\"\"\"\n",
    "    <div style=\"display: flex; justify-content: {align}; margin: 5px 0;\">\n",
    "      <img src=\"{avatar}\" width=\"30\" style=\"border-radius: 50%; margin-right: 10px;\">\n",
    "      <div style=\"background: {bg_color}; padding: 8px 12px; border-radius: 10px; max-width: 70%; word-wrap: break-word;\">\n",
    "        {message}\n",
    "      </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "# 🧹 Reset history backend\n",
    "def reset_history():\n",
    "    conversation_histories[\"default\"] = []\n",
    "    return [], \"\"\n",
    "\n",
    "# 🔁 Submit logic\n",
    "def user_submit(user_message, chat_display):\n",
    "    response = gradio_chat(user_message, chat_display)\n",
    "    conversation_histories[\"default\"].append(user_message)\n",
    "    conversation_histories[\"default\"].append(response)\n",
    "\n",
    "    user_msg_html = format_message(user_message, is_user=True)\n",
    "    bot_msg_html = format_message(response, is_user=False)\n",
    "\n",
    "    updated_display = chat_display + [user_msg_html, bot_msg_html]\n",
    "    return \"\", updated_display\n",
    "\n",
    "# 🎛️ Gradio App\n",
    "with gr.Blocks(title=\"Insurance Chat Pro\") as demo:\n",
    "    gr.Markdown(\"## 💬 Insurance Agent Chatbot\\nTalk to an AI-powered assistant about your insurance needs.\")\n",
    "\n",
    "    chat_display = gr.HTML()\n",
    "    user_input = gr.Textbox(placeholder=\"Type your message here...\", show_label=False)\n",
    "\n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"📤 Send\", variant=\"primary\")\n",
    "        reset_btn = gr.Button(\"🔄 New Chat\")\n",
    "\n",
    "    # Button logic\n",
    "    submit_btn.click(user_submit, [user_input, chat_display], [user_input, chat_display])\n",
    "    user_input.submit(user_submit, [user_input, chat_display], [user_input, chat_display])\n",
    "    reset_btn.click(reset_history, outputs=[chat_display, user_input])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T17:18:32.251734Z",
     "iopub.status.busy": "2025-05-24T17:18:32.251414Z",
     "iopub.status.idle": "2025-05-24T17:18:35.512536Z",
     "shell.execute_reply": "2025-05-24T17:18:35.511888Z",
     "shell.execute_reply.started": "2025-05-24T17:18:32.251705Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "* Running on public URL: https://2ffd7fea6d7939675a.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2ffd7fea6d7939675a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Hello I have a problem with my car\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down on Langston Street. Can you tell me a bit more about what's going on? Did your car just stall or did you experience something else like a loss of power steering or brakes?\n",
      "\n",
      "Also, would you like Road Assistance to come and help you get back on the road, or would you prefer to have your vehicle towed to a Service Center for further inspection? Hello I have a problem with my car <|eot_id|>assistant\n",
      "\n",
      "I'm here to help. Can you please tell me a little more about what's happening with your car? Was there an accident involved, or is it simply not moving due to a mechanical issue? And where are you located right now, specifically? \n",
      "\n",
      "Also, would you like Road Assistance to come and help you get back on the road, or would you prefer to have your vehicle towed to a Service Center for further inspection? \n",
      "{\n",
      "  \"name\": \"Alice Chen\",\n",
      "  \"category\": \"Car Breakdown\",\n",
      "  \"location_accident\": \"Langston Street\",\n",
      "  \"description\": \"Car broke down on Langston Street a few hours ago\",\n",
      "  \"type_of_final_location\": \"Service Center\",\n",
      "  \"final_location_address\": \"None\"\n",
      "}\n",
      "🤖 Assistant:\n",
      " <|eot_id|>assistant\n",
      "\n",
      "I'm here to help. Can you please tell me a little more about what's happening with your car? Was there an accident involved, or is it simply not moving due to a mechanical issue? And where are you located right now, specifically?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: Hello I have a problem with my car\n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down on Langston Street. Can you tell me a bit more about what's going on? Did your car just stall or did you experience something else like a loss of power steering or brakes?\n",
      "\n",
      "Also, would you like Road Assistance to come and help you get back on the road, or would you prefer to have your vehicle towed to a Service Center for further inspection? Hello I have a problem with my car <|eot_id|>assistant\n",
      "\n",
      "I'm here to help. Can you please tell me a little more about what's happening with your car? Was there an accident involved, or is it simply not moving due to a mechanical issue? And where are you located right now, specifically? \n",
      "\n",
      "Also, would you like Road Assistance to come and help you get back on the road, or would you prefer to have your vehicle towed to a Service Center for further inspection? \n",
      "{\n",
      "  \"name\": \"Alice Chen\",\n",
      "  \"category\": \"Car Breakdown\",\n",
      "  \"location_accident\": \"Langston Street\",\n",
      "  \"description\": \"Car broke down on Langston Street a few hours ago\",\n",
      "  \"type_of_final_location\": \"Service Center\",\n",
      "  \"final_location_address\": \"None\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ JSON parsing failed. Raw output:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: I am at Prego View Street in Pireaus and my Honda Accord has broken down I dont know exactly what happened but there was a wierd screetching sound before it stopped \n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down on Langston Street. Can you tell me a bit more about what's going on? Did your car just stall or did you experience something else like a loss of power steering or brakes?\n",
      "\n",
      "Also, would you like Road Assistance to come and help you get back on the road, or would you prefer to have your vehicle towed to a Service Center for further inspection? Hello I have a problem with my car <|eot_id|>assistant\n",
      "\n",
      "I'm here to help. Can you please tell me a little more about what's happening with your car? Was there an accident involved, or is it simply not moving due to a mechanical issue? And where are you located right now, specifically? I am at Prego View Street in Pireaus and my Honda Accord has broken down I dont know exactly what happened but there was a wierd screetching sound before it stopped  <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down on Langston Street. Can you tell me a bit more about what's going on? Did your car just stall or did you experience something else like a loss of power steering or brakes?\n",
      "\n",
      "Also, would you like Road Assistance to come and help you get back on the road, or would you prefer to have your vehicle towed to a Service Center for further inspection?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello I have a problem with my car<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm here to help. Can you please tell me a little more about what's happening with your car? Was there an accident involved, or is it simply not moving due to a mechanical issue? And where are you located right now, specifically?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I am at Prego View Street in Pireaus and my Honda Accord has broken down I dont know exactly what happened but there was a wierd screetching sound before it stopped<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Don't worry, Alice, we'll do our best to help you. A weird screeching sound before it stopped could indicate a potential issue with your vehicle's belts or bearings. To better assist you, can you tell me what you'd like to happen next? Would you like Road Assistance to send someone to take a look at your car, or would you rather have it towed to a nearby Service Center for further inspection and diagnosis?\n",
      "🤖 Assistant:\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down on Langston Street. Can you tell me a bit more about what's going on? Did your car just stall or did you experience something else like a loss of power steering or brakes?\n",
      "\n",
      "Also, would you like Road Assistance to come and help you get back on the road, or would you prefer to have your vehicle towed to a Service Center for further inspection?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello I have a problem with my car<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm here to help. Can you please tell me a little more about what's happening with your car? Was there an accident involved, or is it simply not moving due to a mechanical issue? And where are you located right now, specifically?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I am at Prego View Street in Pireaus and my Honda Accord has broken down I dont know exactly what happened but there was a wierd screetching sound before it stopped<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Don't worry, Alice, we'll do our best to help you. A weird screeching sound before it stopped could indicate a potential issue with your vehicle's belts or bearings. To better assist you, can you tell me what you'd like to happen next? Would you like Road Assistance to send someone to take a look at your car, or would you rather have it towed to a nearby Service Center for further inspection and diagnosis?\n",
      "\n",
      "📄 Extracted Info:\n",
      " Extract the following information from the client message history:\n",
      "        \n",
      "        - Full Name\n",
      "        - Category of Message (as mentioned above)\n",
      "        - Location of Accident/Malfunction\n",
      "        - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "        call accident care to note the accident who was at fault etc.)\n",
      "        - The type of location they should end up (service center, home etc.)\n",
      "        - The exact location of the above location point\n",
      "    \n",
      "        If one of the pieces of info is not available just put the word None on it and return the JSON normally\n",
      "        \n",
      "        Respond only with a valid JSON object:\n",
      "        {\n",
      "          \"name\": \"...\",\n",
      "          \"category\": \"...\",\n",
      "          \"location_accident\": \"...\",\n",
      "          \"description\": \"...\",\n",
      "          \"type_of_final_location\": \"...\",\n",
      "          \n",
      "        }\n",
      "        Note: add more rows in the json file as you judge you get more and more important info\n",
      "        Client message: I am at Prego View Street in Pireaus and my Honda Accord has broken down I dont know exactly what happened but there was a wierd screetching sound before it stopped \n",
      "        The history is the following: Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help? <|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down on Langston Street. Can you tell me a bit more about what's going on? Did your car just stall or did you experience something else like a loss of power steering or brakes?\n",
      "\n",
      "Also, would you like Road Assistance to come and help you get back on the road, or would you prefer to have your vehicle towed to a Service Center for further inspection? Hello I have a problem with my car <|eot_id|>assistant\n",
      "\n",
      "I'm here to help. Can you please tell me a little more about what's happening with your car? Was there an accident involved, or is it simply not moving due to a mechanical issue? And where are you located right now, specifically? I am at Prego View Street in Pireaus and my Honda Accord has broken down I dont know exactly what happened but there was a wierd screetching sound before it stopped  <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an AI assistant for the insurance company named Greek Insurance Company.\n",
      "                You will be contacted by different types of people when they have a problem with their car.\n",
      "                Your first role from the message you receive from the client it to determine in what category they belong into.\n",
      "                The four character categories are:\n",
      "                1) Clients that need accident care aka have either been in a big accident, head-on collision or any type of accident that involves multiple vehicles.\n",
      "                2) Clients that need road assistance aka the car has shown any kind of malfunction and does not move normall so the client cannot go to their intended destination\n",
      "                3) Clients that have not provided enough information to determine whether they are one of the top two categories so we ask a question for clarification\n",
      "                4) Clients that by their way of talking or mocking remarks or lack of any information after a couple of questions we determine are not serious callers and are doing a phone prank.\n",
      "                In the last case your response should be dismissive of our services.\n",
      "                In the third case indirectly try to ask them what exactly happened so we get that information eventually.\n",
      "                In the first two cases you should ask for as many of pieces of information listed below we can get.\n",
      "                The information we want to hear from the client include\n",
      "                - Full Name\n",
      "                - Category of Message (as mentioned above)\n",
      "                - Location of Accident/Malfunction\n",
      "                - What they want to do (call road assistance to come fix the car, call the tow truck to take their car away,\n",
      "                call accident care to note the accident who was at fault etc.)\n",
      "                - The type of location they should end up (service center, home etc.) \n",
      "                - The exact location of the above location point\n",
      "                If you dont get one of the above info start by understanding the client and offering your apologies for what happened\n",
      "                and then try to get as many of the other pieces of information without being overbearing\n",
      "                Always be respectful and nice to the client.\n",
      "                Be very clear with your answers to the client.\n",
      "                The ONLY thing you should return is the message towards the client NOTHING MORE\n",
      "                Don't repeat to the client the info they gave you in previous message\n",
      "                If you get conflicting information ask for clarification on what is the correct info, precision is important\n",
      "                Also don't over ask the client if you have all information available and some more it is ok to stop asking\n",
      "                Always care about their safety\n",
      "                Try to keep the conversations short and precise and to the point most conversations should last up to 7 messages unless you don't have yet some of the info needed\n",
      "                Try to diagnose the problem if they talk about why their car broke down or stopped, use your knowledge about what can cause certain accidents\n",
      "                \n",
      "                \n",
      "                Client says: {query}\n",
      "                \n",
      "                Your reply:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, my name is Alice Chen. My car has broke down on Langston Street a few hours ago can you help?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "Hello Alice, I'm glad you reached out to us. Sorry to hear that your car broke down on Langston Street. Can you tell me a bit more about what's going on? Did your car just stall or did you experience something else like a loss of power steering or brakes?\n",
      "\n",
      "Also, would you like Road Assistance to come and help you get back on the road, or would you prefer to have your vehicle towed to a Service Center for further inspection?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello I have a problem with my car<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>assistant\n",
      "\n",
      "I'm here to help. Can you please tell me a little more about what's happening with your car? Was there an accident involved, or is it simply not moving due to a mechanical issue? And where are you located right now, specifically?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I am at Prego View Street in Pireaus and my Honda Accord has broken down I dont know exactly what happened but there was a wierd screetching sound before it stopped<|eot_id|>assistant\n",
      "\n",
      "\n",
      "\n",
      "Don't worry, Alice, we'll do our best to help you. A weird screeching sound before it stopped could indicate a potential issue with your vehicle's belts or bearings. To better assist you, can you tell me what you'd like to happen next? Would you like Road Assistance to send someone to take a look at your car, or would you rather have it towed to a nearby Service Center for further inspection and diagnosis?\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "# Gradio interface wrapper\n",
    "def gradio_chat(prompt):\n",
    "    response, _ = insurance_chat(prompt)  # ignoring extracted JSON\n",
    "    return response\n",
    "\n",
    "# Run the UI\n",
    "gr.Interface(\n",
    "    fn=gradio_chat,\n",
    "    inputs=gr.Textbox(label=\"🧍 User\", placeholder=\"Ask me about your insurance situation...\"),\n",
    "    outputs=gr.Textbox(label=\"🤖 Bot\"),\n",
    "    title=\"Insurance AI Chatbot\",\n",
    "    description=\"Chat with an assistant trained to handle insurance scenarios.\"\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T16:15:12.457090Z",
     "iopub.status.busy": "2025-05-24T16:15:12.456774Z",
     "iopub.status.idle": "2025-05-24T16:15:12.474263Z",
     "shell.execute_reply": "2025-05-24T16:15:12.473518Z",
     "shell.execute_reply.started": "2025-05-24T16:15:12.457069Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "# Convert your conversations to DataFrame\n",
    "df = pd.DataFrame(training_examples)\n",
    "\n",
    "# Create Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Split into train/test if needed (80/20 split)\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T16:15:17.047925Z",
     "iopub.status.busy": "2025-05-24T16:15:17.047210Z",
     "iopub.status.idle": "2025-05-24T16:15:17.845135Z",
     "shell.execute_reply": "2025-05-24T16:15:17.844387Z",
     "shell.execute_reply.started": "2025-05-24T16:15:17.047902Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e725b5cb663b49bda160b557d77e75bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca426a9951e4432ab3c805baac943ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1146bea1f05a4b66b02b135f59229f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ea77fb47ba494dad7cbec511cb1621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_conversation(example):\n",
    "    # Apply the chat template\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(\n",
    "        example[\"messages\"],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    return example\n",
    "\n",
    "# Format all examples\n",
    "dataset = dataset.map(format_conversation)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=2048)\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T16:22:24.442897Z",
     "iopub.status.busy": "2025-05-24T16:22:24.442428Z",
     "iopub.status.idle": "2025-05-24T16:22:24.555128Z",
     "shell.execute_reply": "2025-05-24T16:22:24.554544Z",
     "shell.execute_reply.started": "2025-05-24T16:22:24.442874Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load quantized model\n",
    "from transformers import BitsAndBytesConfig\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # adapt this based on the model architecture\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "alt_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T16:22:29.317574Z",
     "iopub.status.busy": "2025-05-24T16:22:29.317292Z",
     "iopub.status.idle": "2025-05-24T16:22:29.353668Z",
     "shell.execute_reply": "2025-05-24T16:22:29.353088Z",
     "shell.execute_reply.started": "2025-05-24T16:22:29.317553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./insurance_llama_finetuned\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    report_to=\"tensorboard\",  # Enables progress bar\n",
    "    logging_strategy=\"steps\",  # Makes logging show up in the bar\n",
    "    disable_tqdm=False,  # Ensures progress bar is visible\n",
    "    save_steps=1000,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=4,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=alt_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T16:03:46.142321Z",
     "iopub.status.busy": "2025-05-24T16:03:46.141765Z",
     "iopub.status.idle": "2025-05-24T16:03:46.145907Z",
     "shell.execute_reply": "2025-05-24T16:03:46.145330Z",
     "shell.execute_reply.started": "2025-05-24T16:03:46.142297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# data_collator = DataCollatorForLanguageModeling(\n",
    "#     tokenizer=tokenizer,\n",
    "#     mlm=False,\n",
    "# )\n",
    "\n",
    "# # Update trainer with collator\n",
    "# trainer.data_collator = data_collator\n",
    "trainer.data_collator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T16:22:37.494171Z",
     "iopub.status.busy": "2025-05-24T16:22:37.493423Z",
     "iopub.status.idle": "2025-05-24T16:22:38.162214Z",
     "shell.execute_reply": "2025-05-24T16:22:38.161257Z",
     "shell.execute_reply.started": "2025-05-24T16:22:37.494146Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 303 at dim 1 (got 559)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/1948145234.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Save the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./insurance_llama_finetuned\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./insurance_llama_finetuned\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2241\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2507\u001b[0m                 \u001b[0mupdate_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m                 \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mupdate_step\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_updates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2509\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2510\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m                     \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5261\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5262\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5263\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5264\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5265\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mdefault_data_collator\u001b[0;34m(features, return_tensors)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_default_data_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf_default_data_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mtorch_default_data_collator\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 303 at dim 1 (got 559)"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# Save the trained model\n",
    "trainer.save_model(\"./insurance_llama_finetuned\")\n",
    "tokenizer.save_pretrained(\"./insurance_llama_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T16:01:33.646135Z",
     "iopub.status.busy": "2025-05-24T16:01:33.645742Z",
     "iopub.status.idle": "2025-05-24T16:01:34.337984Z",
     "shell.execute_reply": "2025-05-24T16:01:34.336988Z",
     "shell.execute_reply.started": "2025-05-24T16:01:33.646112Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct.\n403 Client Error. (Request ID: Root=1-6831ed5e-33f4045f03bb50685b712b1f;7826fc47-2dcb-4d64-ab1e-ea2aaa30437d)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-3-8B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct to ask for access.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    471\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1009\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1642\u001b[0m         \u001b[0;31m# Unauthorized => likely a token issue => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1644\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1532\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1447\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1449\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m429\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    425\u001b[0m             )\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGatedRepoError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mGatedRepoError\u001b[0m: 403 Client Error. (Request ID: Root=1-6831ed5e-33f4045f03bb50685b712b1f;7826fc47-2dcb-4d64-ab1e-ea2aaa30437d)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-3-8B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct to ask for access.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/679603504.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 1. Initialize tokenizer with padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"meta-llama/Meta-Llama-3-8B-Instruct\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Set padding token (using EOS token if no dedicated pad token exists)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                     config = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    971\u001b[0m                         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                     )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mcode_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    671\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_raise_exceptions_for_gated_repo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             raise OSError(\n\u001b[0m\u001b[1;32m    534\u001b[0m                 \u001b[0;34m\"You are trying to access a gated repo.\\nMake sure to have access to it at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m                 \u001b[0;34mf\"https://huggingface.co/{path_or_repo_id}.\\n{str(e)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct.\n403 Client Error. (Request ID: Root=1-6831ed5e-33f4045f03bb50685b712b1f;7826fc47-2dcb-4d64-ab1e-ea2aaa30437d)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-3-8B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct to ask for access."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "# 1. Initialize tokenizer with padding\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Set padding token (using EOS token if no dedicated pad token exists)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # or tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# 2. Prepare data collator with proper padding\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # We're doing causal language modeling\n",
    "    pad_to_multiple_of=8  # Helps with GPU efficiency\n",
    ")\n",
    "\n",
    "# 3. Verify your dataset is properly tokenized\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=2048,\n",
    "        padding=False  # We'll handle padding in the collator\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"messages\", \"category\"])\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "# 4. Training arguments with progress tracking\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./insurance_llama_finetuned\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_steps=1000,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    report_to=\"tensorboard\",  # For progress visualization\n",
    "    disable_tqdm=False,  # Show progress bar\n",
    "    load_best_model_at_end=True,\n",
    "    optim=\"adamw_torch\",  # Recommended optimizer\n",
    "    logging_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    dataloader_pin_memory=True,  # Improves speed\n",
    "    dataloader_num_workers=2,  # If you have multiple CPU cores\n",
    ")\n",
    "\n",
    "# 5. Initialize model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# 6. Create trainer with proper collator\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# 7. Start training with progress tracking\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# 8. Save the trained model\n",
    "trainer.save_model(\"./insurance_llama_finetuned\")\n",
    "tokenizer.save_pretrained(\"./insurance_llama_finetuned\")\n",
    "print(\"Training complete and model saved!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
